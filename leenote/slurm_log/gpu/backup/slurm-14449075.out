rhel8/default-icl(17):ERROR:105: Unable to locate a modulefile for 'intel-oneapi-compilers/2022.1.0/gcc'
rhel8/default-icl(18):ERROR:105: Unable to locate a modulefile for 'intel-oneapi-mpi/2021.6.0/intel'
==================== Activating conda environment ====================
> Python version : /home/zl525/.conda/envs/DeepPersonality/bin/python
==================== Run program ====================
wandb: Currently logged in as: 1009694687 (hyllbd-1009694687). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /home/zl525/code/DeepPersonality/wandb/run-20230216_000516-jwohy7td
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-microwave-396
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hyllbd-1009694687/DeepPersonality
wandb: üöÄ View run at https://wandb.ai/hyllbd-1009694687/DeepPersonality/runs/jwohy7td
{
    "DATA":{
        "ANIMALS_TEST_AUD_DATA":"udiva_full/test/recordings/animals_recordings_test_wav",
        "ANIMALS_TEST_IMG_DATA":"udiva_full/test/recordings/animals_recordings_test_img",
        "ANIMALS_TRAIN_AUD_DATA":"udiva_full/train/recordings/animals_recordings_train_wav",
        "ANIMALS_TRAIN_IMG_DATA":"udiva_full/train/recordings/animals_recordings_train_img",
        "ANIMALS_VAL_AUD_DATA":"udiva_full/val/recordings/animals_recordings_val_wav",
        "ANIMALS_VAL_IMG_DATA":"udiva_full/val/recordings/animals_recordings_val_img",
        "GHOST_TEST_AUD_DATA":"udiva_full/test/recordings/ghost_recordings_test_wav",
        "GHOST_TEST_IMG_DATA":"udiva_full/test/recordings/ghost_recordings_test_img",
        "GHOST_TRAIN_AUD_DATA":"udiva_full/train/recordings/ghost_recordings_train_wav",
        "GHOST_TRAIN_IMG_DATA":"udiva_full/train/recordings/ghost_recordings_train_img",
        "GHOST_VAL_AUD_DATA":"udiva_full/val/recordings/ghost_recordings_val_wav",
        "GHOST_VAL_IMG_DATA":"udiva_full/val/recordings/ghost_recordings_val_img",
        "LEGO_TEST_AUD_DATA":"udiva_full/test/recordings/lego_recordings_test_wav",
        "LEGO_TEST_IMG_DATA":"udiva_full/test/recordings/lego_recordings_test_img",
        "LEGO_TRAIN_AUD_DATA":"udiva_full/train/recordings/lego_recordings_train_wav",
        "LEGO_TRAIN_IMG_DATA":"udiva_full/train/recordings/lego_recordings_train_img",
        "LEGO_VAL_AUD_DATA":"udiva_full/val/recordings/lego_recordings_val_wav",
        "LEGO_VAL_IMG_DATA":"udiva_full/val/recordings/lego_recordings_val_img",
        "ROOT":"datasets",
        "SAMPLE_SIZE":20,
        "SESSION":"TALK",
        "TALK_TEST_AUD_DATA":"udiva_full/test/recordings/talk_recordings_test_wav",
        "TALK_TEST_IMG_DATA":"udiva_full/test/recordings/talk_recordings_test_img",
        "TALK_TRAIN_AUD_DATA":"udiva_full/train/recordings/talk_recordings_train_wav",
        "TALK_TRAIN_IMG_DATA":"udiva_full/train/recordings/talk_recordings_train_img",
        "TALK_VAL_AUD_DATA":"udiva_full/val/recordings/talk_recordings_val_wav",
        "TALK_VAL_IMG_DATA":"udiva_full/val/recordings/talk_recordings_val_img",
        "TEST_AUD_DATA":"raw_voice/testData",
        "TEST_IMG_DATA":"image_data/test_data",
        "TEST_IMG_FACE_DATA":"image_data/test_data_face",
        "TEST_LABEL_DATA":"udiva_full/test/label/sessions_test.pkl",
        "TRAIN_AUD_DATA":"raw_voice/trainingData",
        "TRAIN_IMG_DATA":"image_data/train_data",
        "TRAIN_IMG_FACE_DATA":"image_data/train_data_face",
        "TRAIN_LABEL_DATA":"udiva_full/train/label/sessions_train.pkl",
        "TYPE":"frame",
        "VALID_AUD_DATA":"raw_voice/validationData",
        "VALID_IMG_DATA":"image_data/valid_data",
        "VALID_IMG_FACE_DATA":"image_data/valid_data_face",
        "VALID_LABEL_DATA":"udiva_full/val/label/sessions_val.pkl",
        "VA_DATA":"va_data/cropped_aligned",
        "VA_ROOT":"datasets",
        "VA_TRAIN_LABEL":"va_data/va_label/VA_Set/Train_Set",
        "VA_VALID_LABEL":"va_data/va_label/VA_Set/Validation_Set"
    },
    "DATA_LOADER":{
        "DATASET":"",
        "DATASET_NAME":"UDIVA",
        "DROP_LAST":true,
        "NAME":"bimodal_resnet_lstm_data_loader_udiva",
        "NUM_WORKERS":1,
        "SECOND_STAGE":{
            "METHOD":"",
            "TYPE":""
        },
        "SHUFFLE":true,
        "TRAIN_BATCH_SIZE":16,
        "TRANSFORM":"standard_frame_transform",
        "VALID_BATCH_SIZE":4
    },
    "LOSS":{
        "NAME":"binary_cross_entropy"
    },
    "MODEL":{
        "NAME":"resnet50_3d_model_udiva",
        "NUM_CLASS":5,
        "PRETRAIN":false,
        "RETURN_FEATURE":false,
        "SPECTRUM_CHANNEL":50
    },
    "SOLVER":{
        "BETA_1":0.5,
        "BETA_2":0.999,
        "FACTOR":0.1,
        "LR_INIT":0.0005,
        "MILESTONE":[
            10,
            20,
            40,
            60,
            80,
            100
        ],
        "MOMENTUM":0.9,
        "NAME":"adam",
        "RESET_LR":true,
        "SCHEDULER":"multi_step_scale",
        "WEIGHT_DECAY":0.0005
    },
    "TEST":{
        "COMPUTE_CCC":false,
        "COMPUTE_PCC":false,
        "FULL_TEST":false,
        "SAVE_DATASET_OUTPUT":"",
        "TEST_ONLY":false,
        "WEIGHT":""
    },
    "TRAIN":{
        "BIMODAL_OPTION":1,
        "LOG_INTERVAL":1,
        "MAX_EPOCH":150,
        "OUTPUT_DIR":"results/demo/unified_frame_images/resnet_3d_udiva",
        "PRE_TRAINED_MODEL":null,
        "RESUME":"",
        "START_EPOCH":0,
        "TRAINER":"BiModalTrainerUdiva",
        "VALID_INTERVAL":1
    }
}
change learning rate form [0.0005] to [0.0005]
Training: learning rate:0.0005
Using BCELoss
================================== start training... ==================================
Train: Epo[001/150] Iter[001/007] IterTime:[75.72s] LOSS: 0.6725 Batch ACC:0.5625 (9/16) Epo current ACC:0.5625 (9/16) ETA:22h:13m:58s 

Train: Epo[001/150] Iter[002/007] IterTime:[75.04s] LOSS: 1.0001 Batch ACC:0.5000 (8/16) Epo current ACC:0.5312 (17/32) ETA:22h:0m:41s 

Train: Epo[001/150] Iter[003/007] IterTime:[74.45s] LOSS: 1.7413 Batch ACC:0.6250 (10/16) Epo current ACC:0.5625 (27/48) ETA:21h:49m:0s 

Train: Epo[001/150] Iter[004/007] IterTime:[74.16s] LOSS: 0.9972 Batch ACC:0.7500 (12/16) Epo current ACC:0.6094 (39/64) ETA:21h:42m:46s 

Train: Epo[001/150] Iter[005/007] IterTime:[74.65s] LOSS: 5.7236 Batch ACC:0.3750 (6/16) Epo current ACC:0.5625 (45/80) ETA:21h:50m:10s 

Train: Epo[001/150] Iter[006/007] IterTime:[73.41s] LOSS: 1.5209 Batch ACC:0.6875 (11/16) Epo current ACC:0.5833 (56/96) ETA:21h:27m:3s 

Train: Epo[001/150] Iter[007/007] IterTime:[74.79s] LOSS: 1.0377 Batch ACC:0.6250 (10/16) Epo current ACC:0.5893 (66/112) ETA:21h:50m:1s 

Train: Epo[001/150] Epoch Summary Acc: 0.5892857313156128 (66/112)
tensor([[0.4909, 0.5091],
        [0.5100, 0.4900],
        [0.4684, 0.5316],
        [0.4804, 0.5196],
        [0.4835, 0.5165],
        [0.5060, 0.4940],
        [0.4710, 0.5290],
        [0.4307, 0.5693],
        [0.4196, 0.5804],
        [0.4632, 0.5368],
        [0.4203, 0.5797],
        [0.4951, 0.5049],
        [0.4901, 0.5099],
        [0.4934, 0.5066],
        [0.4994, 0.5006],
        [0.4734, 0.5266]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:0, train loss:0.6725 ***********
tensor([[4.9118e-01, 5.0882e-01],
        [1.9608e-06, 1.0000e+00],
        [9.0803e-01, 9.1969e-02],
        [3.2148e-01, 6.7852e-01],
        [8.8951e-01, 1.1049e-01],
        [7.9046e-01, 2.0954e-01],
        [8.2298e-01, 1.7702e-01],
        [5.4459e-12, 1.0000e+00],
        [5.8466e-01, 4.1534e-01],
        [4.4607e-01, 5.5393e-01],
        [8.2627e-01, 1.7373e-01],
        [8.2787e-01, 1.7213e-01],
        [3.9383e-01, 6.0617e-01],
        [6.2845e-01, 3.7155e-01],
        [3.6775e-01, 6.3225e-01],
        [5.2177e-03, 9.9478e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:1, train loss:1.0001 ***********
tensor([[1.9099e-01, 8.0901e-01],
        [2.7560e-02, 9.7244e-01],
        [1.8439e-03, 9.9816e-01],
        [5.1394e-02, 9.4861e-01],
        [1.6961e-11, 1.0000e+00],
        [1.9932e-01, 8.0068e-01],
        [4.8576e-03, 9.9514e-01],
        [2.0294e-02, 9.7971e-01],
        [2.2328e-01, 7.7672e-01],
        [2.2203e-01, 7.7797e-01],
        [4.1796e-04, 9.9958e-01],
        [1.8619e-01, 8.1381e-01],
        [3.4712e-03, 9.9653e-01],
        [3.4241e-02, 9.6576e-01],
        [1.8167e-01, 8.1833e-01],
        [7.4370e-03, 9.9256e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:2, train loss:1.7413 ***********
tensor([[2.0250e-02, 9.7975e-01],
        [2.0121e-02, 9.7988e-01],
        [2.8735e-02, 9.7127e-01],
        [2.7498e-02, 9.7250e-01],
        [8.8656e-03, 9.9113e-01],
        [7.2430e-09, 1.0000e+00],
        [5.4406e-03, 9.9456e-01],
        [1.8733e-02, 9.8127e-01],
        [2.0650e-02, 9.7935e-01],
        [4.6461e-09, 1.0000e+00],
        [2.0075e-02, 9.7993e-01],
        [2.1748e-02, 9.7825e-01],
        [2.2377e-02, 9.7762e-01],
        [7.7862e-03, 9.9221e-01],
        [1.8399e-02, 9.8160e-01],
        [2.2608e-02, 9.7739e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:3, train loss:0.9972 ***********
tensor([[4.1445e-02, 9.5855e-01],
        [5.6960e-02, 9.4304e-01],
        [5.9830e-02, 9.4017e-01],
        [3.7220e-05, 9.9996e-01],
        [3.5302e-02, 9.6470e-01],
        [3.6453e-02, 9.6355e-01],
        [4.0371e-02, 9.5963e-01],
        [6.5575e-02, 9.3442e-01],
        [4.9103e-02, 9.5090e-01],
        [5.0468e-02, 9.4953e-01],
        [4.7959e-02, 9.5204e-01],
        [3.3791e-02, 9.6621e-01],
        [1.6489e-03, 9.9835e-01],
        [7.4177e-10, 1.0000e+00],
        [5.8308e-02, 9.4169e-01],
        [5.4427e-02, 9.4557e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:4, train loss:5.7236 ***********
Valid: Epo[001/150] Iter[001/004] LOSS: 50.0000 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (2/4)
Valid: Epo[001/150] Iter[002/004] LOSS: 50.0000 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (4/8)
Valid: Epo[001/150] Iter[003/004] LOSS: 74.8653 Batch ACC:0.2500 (1/4) Epo Current ACC:0.4167 (5/12)
Valid: Epo[001/150] Iter[004/004] LOSS: 50.0000 Batch ACC:0.5000 (2/4) Epo Current ACC:0.4375 (7/16)
Valid: Epo[001/150] Train Mean_Acc: 58.93% Valid Mean_Acc:43.75% OCEAN_ACC:0.4375 Epo Summary Acc:0.4375 (7/16)

Training: learning rate:0.0005
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:0, val loss:50.0000 ***********
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:1, val loss:50.0000 ***********
tensor([[0.0000e+00, 1.0000e+00],
        [0.0000e+00, 1.0000e+00],
        [1.0930e-43, 1.0000e+00],
        [0.0000e+00, 1.0000e+00]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:2, val loss:74.8653 ***********
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:3, val loss:50.0000 ***********
Train: Epo[002/150] Iter[001/007] IterTime:[74.76s] LOSS: 0.9993 Batch ACC:0.5000 (8/16) Epo current ACC:0.5000 (8/16) ETA:21h:48m:22s 

Train: Epo[002/150] Iter[002/007] IterTime:[73.74s] LOSS: 1.5513 Batch ACC:0.3125 (5/16) Epo current ACC:0.4062 (13/32) ETA:21h:29m:12s 

Train: Epo[002/150] Iter[003/007] IterTime:[73.99s] LOSS: 1.4336 Batch ACC:0.3750 (6/16) Epo current ACC:0.3958 (19/48) ETA:21h:32m:26s 

Train: Epo[002/150] Iter[004/007] IterTime:[73.15s] LOSS: 1.9017 Batch ACC:0.2500 (4/16) Epo current ACC:0.3594 (23/64) ETA:21h:16m:26s 

Train: Epo[002/150] Iter[005/007] IterTime:[73.26s] LOSS: 2.1408 Batch ACC:0.3750 (6/16) Epo current ACC:0.3625 (29/80) ETA:21h:17m:8s 

Train: Epo[002/150] Iter[006/007] IterTime:[72.79s] LOSS: 1.6626 Batch ACC:0.3750 (6/16) Epo current ACC:0.3646 (35/96) ETA:21h:7m:47s 

Train: Epo[002/150] Iter[007/007] IterTime:[72.98s] LOSS: 1.4417 Batch ACC:0.4375 (7/16) Epo current ACC:0.3750 (42/112) ETA:21h:9m:56s 

Train: Epo[002/150] Epoch Summary Acc: 0.375 (42/112)
tensor([[0.1574, 0.8426],
        [0.1700, 0.8300],
        [0.2260, 0.7740],
        [0.2066, 0.7934],
        [0.1680, 0.8320],
        [0.4349, 0.5651],
        [0.2549, 0.7451],
        [0.2759, 0.7241],
        [0.1639, 0.8361],
        [0.3214, 0.6786],
        [0.1515, 0.8485],
        [0.8730, 0.1270],
        [0.7663, 0.2337],
        [0.1348, 0.8652],
        [0.2025, 0.7975],
        [0.1475, 0.8525]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:0, train loss:0.9993 ***********
tensor([[0.3148, 0.6852],
        [0.4584, 0.5416],
        [0.9649, 0.0351],
        [0.9854, 0.0146],
        [0.9282, 0.0718],
        [0.9292, 0.0708],
        [0.9593, 0.0407],
        [0.2048, 0.7952],
        [0.2151, 0.7849],
        [0.2934, 0.7066],
        [0.2039, 0.7961],
        [0.3060, 0.6940],
        [0.1809, 0.8191],
        [0.2102, 0.7898],
        [0.1743, 0.8257],
        [0.3234, 0.6766]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:1, train loss:1.5513 ***********
tensor([[6.9850e-01, 3.0150e-01],
        [9.9948e-01, 5.1801e-04],
        [3.9574e-01, 6.0426e-01],
        [7.3107e-01, 2.6893e-01],
        [8.4967e-01, 1.5033e-01],
        [9.9304e-01, 6.9596e-03],
        [3.9506e-01, 6.0494e-01],
        [6.5612e-01, 3.4388e-01],
        [7.3874e-01, 2.6126e-01],
        [6.4441e-01, 3.5559e-01],
        [8.9012e-01, 1.0988e-01],
        [5.1940e-01, 4.8060e-01],
        [9.8650e-01, 1.3504e-02],
        [4.6874e-01, 5.3126e-01],
        [4.7191e-01, 5.2809e-01],
        [5.4943e-01, 4.5057e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:2, train loss:1.4336 ***********
tensor([[0.8353, 0.1647],
        [0.7235, 0.2765],
        [0.7288, 0.2712],
        [0.7723, 0.2277],
        [0.9936, 0.0064],
        [0.7177, 0.2823],
        [0.9984, 0.0016],
        [0.9852, 0.0148],
        [0.9028, 0.0972],
        [0.9751, 0.0249],
        [0.7726, 0.2274],
        [0.7350, 0.2650],
        [0.7128, 0.2872],
        [0.9239, 0.0761],
        [0.7660, 0.2340],
        [0.9929, 0.0071]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:3, train loss:1.9017 ***********
tensor([[8.3471e-01, 1.6529e-01],
        [8.7603e-01, 1.2397e-01],
        [9.5396e-01, 4.6041e-02],
        [8.3195e-01, 1.6805e-01],
        [8.3606e-01, 1.6394e-01],
        [8.5262e-01, 1.4738e-01],
        [8.3602e-01, 1.6398e-01],
        [8.3604e-01, 1.6396e-01],
        [9.9787e-01, 2.1333e-03],
        [8.3310e-01, 1.6690e-01],
        [9.8847e-01, 1.1534e-02],
        [9.9952e-01, 4.8140e-04],
        [9.7598e-01, 2.4023e-02],
        [8.5991e-01, 1.4009e-01],
        [9.8425e-01, 1.5752e-02],
        [8.2706e-01, 1.7294e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:4, train loss:2.1408 ***********
Valid: Epo[002/150] Iter[001/004] LOSS: 50.0000 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (2/4)
Valid: Epo[002/150] Iter[002/004] LOSS: 50.0000 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (4/8)
Valid: Epo[002/150] Iter[003/004] LOSS: 25.0000 Batch ACC:0.7500 (3/4) Epo Current ACC:0.5833 (7/12)
Valid: Epo[002/150] Iter[004/004] LOSS: 25.0000 Batch ACC:0.7500 (3/4) Epo Current ACC:0.6250 (10/16)
Valid: Epo[002/150] Train Mean_Acc: 37.50% Valid Mean_Acc:62.50% OCEAN_ACC:0.625 Epo Summary Acc:0.625 (10/16)

Training: learning rate:0.0005
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:0, val loss:50.0000 ***********
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:1, val loss:50.0000 ***********
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:2, val loss:25.0000 ***********
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:3, val loss:25.0000 ***********
Train: Epo[003/150] Iter[001/007] IterTime:[73.56s] LOSS: 1.2243 Batch ACC:0.2500 (4/16) Epo current ACC:0.2500 (4/16) ETA:21h:18m:43s 

Train: Epo[003/150] Iter[002/007] IterTime:[76.50s] LOSS: 0.7548 Batch ACC:0.4375 (7/16) Epo current ACC:0.3438 (11/32) ETA:22h:8m:37s 

Train: Epo[003/150] Iter[003/007] IterTime:[73.89s] LOSS: 0.6254 Batch ACC:0.4375 (7/16) Epo current ACC:0.3750 (18/48) ETA:21h:21m:58s 

Train: Epo[003/150] Iter[004/007] IterTime:[73.17s] LOSS: 0.6805 Batch ACC:0.5625 (9/16) Epo current ACC:0.4219 (27/64) ETA:21h:8m:14s 

Train: Epo[003/150] Iter[005/007] IterTime:[74.13s] LOSS: 1.3743 Batch ACC:0.5000 (8/16) Epo current ACC:0.4375 (35/80) ETA:21h:23m:36s 

Train: Epo[003/150] Iter[006/007] IterTime:[72.76s] LOSS: 1.5788 Batch ACC:0.5625 (9/16) Epo current ACC:0.4583 (44/96) ETA:20h:58m:44s 

Train: Epo[003/150] Iter[007/007] IterTime:[72.59s] LOSS: 1.1572 Batch ACC:0.5625 (9/16) Epo current ACC:0.4732 (53/112) ETA:20h:54m:35s 

Train: Epo[003/150] Epoch Summary Acc: 0.4732142984867096 (53/112)
tensor([[0.7884, 0.2116],
        [0.7589, 0.2411],
        [0.6752, 0.3248],
        [0.8159, 0.1841],
        [0.8136, 0.1864],
        [0.7072, 0.2928],
        [0.8910, 0.1090],
        [0.6984, 0.3016],
        [0.8061, 0.1939],
        [0.7924, 0.2076],
        [0.7634, 0.2366],
        [0.8139, 0.1861],
        [0.7804, 0.2196],
        [0.7901, 0.2099],
        [0.7383, 0.2617],
        [0.7567, 0.2433]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:0, train loss:1.2243 ***********
tensor([[0.4508, 0.5492],
        [0.6715, 0.3285],
        [0.5918, 0.4082],
        [0.5780, 0.4220],
        [0.6020, 0.3980],
        [0.6692, 0.3308],
        [0.6628, 0.3372],
        [0.6467, 0.3533],
        [0.6273, 0.3727],
        [0.6603, 0.3397],
        [0.6787, 0.3213],
        [0.5324, 0.4676],
        [0.6742, 0.3258],
        [0.6075, 0.3925],
        [0.6718, 0.3282],
        [0.3886, 0.6114]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:1, train loss:0.7548 ***********
tensor([[0.5317, 0.4683],
        [0.5611, 0.4389],
        [0.5534, 0.4466],
        [0.4432, 0.5568],
        [0.1027, 0.8973],
        [0.5132, 0.4868],
        [0.1425, 0.8575],
        [0.5506, 0.4494],
        [0.3775, 0.6225],
        [0.5618, 0.4382],
        [0.5341, 0.4659],
        [0.4380, 0.5620],
        [0.5462, 0.4538],
        [0.2874, 0.7126],
        [0.3574, 0.6426],
        [0.4976, 0.5024]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:2, train loss:0.6254 ***********
tensor([[0.3272, 0.6728],
        [0.4539, 0.5461],
        [0.2054, 0.7946],
        [0.0665, 0.9335],
        [0.4650, 0.5350],
        [0.3972, 0.6028],
        [0.1631, 0.8369],
        [0.3031, 0.6969],
        [0.0818, 0.9182],
        [0.2871, 0.7129],
        [0.0223, 0.9777],
        [0.4581, 0.5419],
        [0.2891, 0.7109],
        [0.4672, 0.5328],
        [0.4600, 0.5400],
        [0.4443, 0.5557]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:3, train loss:0.6805 ***********
tensor([[8.1697e-02, 9.1830e-01],
        [2.8304e-01, 7.1696e-01],
        [2.0688e-01, 7.9312e-01],
        [7.6643e-02, 9.2336e-01],
        [2.7405e-01, 7.2595e-01],
        [2.7395e-01, 7.2605e-01],
        [2.9427e-01, 7.0573e-01],
        [2.3119e-01, 7.6881e-01],
        [2.9370e-01, 7.0630e-01],
        [2.9770e-01, 7.0230e-01],
        [1.9864e-01, 8.0136e-01],
        [2.9758e-01, 7.0242e-01],
        [1.4007e-04, 9.9986e-01],
        [2.9906e-01, 7.0094e-01],
        [1.2264e-01, 8.7736e-01],
        [2.9427e-01, 7.0573e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:4, train loss:1.3743 ***********
Valid: Epo[003/150] Iter[001/004] LOSS: 75.0000 Batch ACC:0.2500 (1/4) Epo Current ACC:0.2500 (1/4)
Valid: Epo[003/150] Iter[002/004] LOSS: 25.0000 Batch ACC:0.7500 (3/4) Epo Current ACC:0.5000 (4/8)
Valid: Epo[003/150] Iter[003/004] LOSS: 75.0000 Batch ACC:0.2500 (1/4) Epo Current ACC:0.4167 (5/12)
Valid: Epo[003/150] Iter[004/004] LOSS: 100.0000 Batch ACC:0.0000 (0/4) Epo Current ACC:0.3125 (5/16)
Valid: Epo[003/150] Train Mean_Acc: 47.32% Valid Mean_Acc:31.25% OCEAN_ACC:0.3125 Epo Summary Acc:0.3125 (5/16)

Training: learning rate:0.0005
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:0, val loss:75.0000 ***********
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:1, val loss:25.0000 ***********
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:2, val loss:75.0000 ***********
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:3, val loss:100.0000 ***********
Train: Epo[004/150] Iter[001/007] IterTime:[74.42s] LOSS: 1.0218 Batch ACC:0.6875 (11/16) Epo current ACC:0.6875 (11/16) ETA:21h:25m:3s 

Train: Epo[004/150] Iter[002/007] IterTime:[72.83s] LOSS: 0.8648 Batch ACC:0.7500 (12/16) Epo current ACC:0.7188 (23/32) ETA:20h:56m:17s 

Train: Epo[004/150] Iter[003/007] IterTime:[74.98s] LOSS: 1.2182 Batch ACC:0.6250 (10/16) Epo current ACC:0.6875 (33/48) ETA:21h:32m:9s 

Train: Epo[004/150] Iter[004/007] IterTime:[73.71s] LOSS: 2.3168 Batch ACC:0.4375 (7/16) Epo current ACC:0.6250 (40/64) ETA:21h:9m:5s 

Train: Epo[004/150] Iter[005/007] IterTime:[71.88s] LOSS: 1.9278 Batch ACC:0.5000 (8/16) Epo current ACC:0.6000 (48/80) ETA:20h:36m:20s 

Train: Epo[004/150] Iter[006/007] IterTime:[75.51s] LOSS: 0.7033 Batch ACC:0.6875 (11/16) Epo current ACC:0.6146 (59/96) ETA:21h:37m:32s 

Train: Epo[004/150] Iter[007/007] IterTime:[72.33s] LOSS: 1.0524 Batch ACC:0.5625 (9/16) Epo current ACC:0.6071 (68/112) ETA:20h:41m:38s 

Train: Epo[004/150] Epoch Summary Acc: 0.6071428656578064 (68/112)
tensor([[9.6672e-02, 9.0333e-01],
        [1.0576e-01, 8.9424e-01],
        [1.1750e-01, 8.8250e-01],
        [1.1968e-01, 8.8032e-01],
        [8.4828e-02, 9.1517e-01],
        [1.1876e-01, 8.8124e-01],
        [2.4672e-05, 9.9998e-01],
        [1.1229e-01, 8.8771e-01],
        [1.1973e-01, 8.8027e-01],
        [5.6143e-02, 9.4386e-01],
        [1.1844e-01, 8.8156e-01],
        [1.4563e-02, 9.8544e-01],
        [1.1932e-01, 8.8068e-01],
        [2.2726e-02, 9.7727e-01],
        [8.3475e-02, 9.1652e-01],
        [3.5212e-02, 9.6479e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:0, train loss:1.0218 ***********
tensor([[0.0732, 0.9268],
        [0.0050, 0.9950],
        [0.0743, 0.9257],
        [0.0034, 0.9966],
        [0.0028, 0.9972],
        [0.0784, 0.9216],
        [0.0771, 0.9229],
        [0.0024, 0.9976],
        [0.0350, 0.9650],
        [0.0752, 0.9248],
        [0.0758, 0.9242],
        [0.0184, 0.9816],
        [0.0024, 0.9976],
        [0.0344, 0.9656],
        [0.0787, 0.9213],
        [0.0210, 0.9790]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:1, train loss:0.8648 ***********
tensor([[2.5677e-05, 9.9997e-01],
        [2.1409e-02, 9.7859e-01],
        [7.7212e-02, 9.2279e-01],
        [7.5336e-02, 9.2466e-01],
        [6.8698e-02, 9.3130e-01],
        [7.2464e-02, 9.2754e-01],
        [7.8817e-02, 9.2118e-01],
        [1.8326e-02, 9.8167e-01],
        [5.1846e-04, 9.9948e-01],
        [7.3981e-02, 9.2602e-01],
        [7.3485e-02, 9.2652e-01],
        [1.1434e-02, 9.8857e-01],
        [1.9069e-02, 9.8093e-01],
        [7.3223e-02, 9.2678e-01],
        [7.4552e-02, 9.2545e-01],
        [7.3792e-02, 9.2621e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:2, train loss:1.2182 ***********
tensor([[9.2345e-02, 9.0766e-01],
        [7.1841e-02, 9.2816e-01],
        [9.2197e-02, 9.0780e-01],
        [9.4379e-03, 9.9056e-01],
        [8.7426e-02, 9.1257e-01],
        [9.5339e-03, 9.9047e-01],
        [9.2101e-02, 9.0790e-01],
        [8.9857e-02, 9.1014e-01],
        [8.9607e-02, 9.1039e-01],
        [4.9566e-03, 9.9504e-01],
        [8.9815e-02, 9.1018e-01],
        [8.9206e-03, 9.9108e-01],
        [9.1691e-02, 9.0831e-01],
        [2.5204e-05, 9.9997e-01],
        [1.8842e-02, 9.8116e-01],
        [9.3117e-02, 9.0688e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:3, train loss:2.3168 ***********
tensor([[2.4278e-02, 9.7572e-01],
        [1.0882e-01, 8.9118e-01],
        [1.1169e-01, 8.8831e-01],
        [5.5101e-05, 9.9994e-01],
        [2.9845e-02, 9.7016e-01],
        [1.9228e-02, 9.8077e-01],
        [1.1096e-01, 8.8904e-01],
        [1.1189e-01, 8.8811e-01],
        [1.0649e-01, 8.9351e-01],
        [9.7301e-02, 9.0270e-01],
        [1.0659e-01, 8.9341e-01],
        [1.0921e-02, 9.8908e-01],
        [2.1115e-02, 9.7889e-01],
        [2.6415e-02, 9.7359e-01],
        [6.5636e-03, 9.9344e-01],
        [1.0275e-01, 8.9725e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:4, train loss:1.9278 ***********
Valid: Epo[004/150] Iter[001/004] LOSS: 66.1845 Batch ACC:0.2500 (1/4) Epo Current ACC:0.2500 (1/4)
Valid: Epo[004/150] Iter[002/004] LOSS: 25.0000 Batch ACC:0.7500 (3/4) Epo Current ACC:0.5000 (4/8)
Valid: Epo[004/150] Iter[003/004] LOSS: 19.0244 Batch ACC:0.7500 (3/4) Epo Current ACC:0.5833 (7/12)
Valid: Epo[004/150] Iter[004/004] LOSS: 89.3358 Batch ACC:0.0000 (0/4) Epo Current ACC:0.4375 (7/16)
Valid: Epo[004/150] Train Mean_Acc: 60.71% Valid Mean_Acc:43.75% OCEAN_ACC:0.4375 Epo Summary Acc:0.4375 (7/16)

Training: learning rate:0.0005
tensor([[0.0000e+00, 1.0000e+00],
        [1.5800e-13, 1.0000e+00],
        [3.3476e-29, 1.0000e+00],
        [0.0000e+00, 1.0000e+00]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:0, val loss:66.1845 ***********
tensor([[0.0000e+00, 1.0000e+00],
        [1.4088e-34, 1.0000e+00],
        [2.3298e-21, 1.0000e+00],
        [3.7850e-40, 1.0000e+00]])
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:1, val loss:25.0000 ***********
tensor([[7.3589e-19, 1.0000e+00],
        [0.0000e+00, 1.0000e+00],
        [2.1471e-23, 1.0000e+00],
        [0.0000e+00, 1.0000e+00]])
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:2, val loss:19.0244 ***********
tensor([[1.9168e-18, 1.0000e+00],
        [8.1225e-33, 1.0000e+00],
        [0.0000e+00, 1.0000e+00],
        [0.0000e+00, 1.0000e+00]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:3, val loss:89.3358 ***********
Train: Epo[005/150] Iter[001/007] IterTime:[72.84s] LOSS: 1.2200 Batch ACC:0.5000 (8/16) Epo current ACC:0.5000 (8/16) ETA:20h:49m:16s 

Train: Epo[005/150] Iter[002/007] IterTime:[72.30s] LOSS: 1.3247 Batch ACC:0.4375 (7/16) Epo current ACC:0.4688 (15/32) ETA:20h:38m:44s 

Train: Epo[005/150] Iter[003/007] IterTime:[72.80s] LOSS: 0.5774 Batch ACC:0.5625 (9/16) Epo current ACC:0.5000 (24/48) ETA:20h:46m:6s 

Train: Epo[005/150] Iter[004/007] IterTime:[72.75s] LOSS: 0.6969 Batch ACC:0.5625 (9/16) Epo current ACC:0.5156 (33/64) ETA:20h:44m:2s 

Train: Epo[005/150] Iter[005/007] IterTime:[72.41s] LOSS: 0.9969 Batch ACC:0.1875 (3/16) Epo current ACC:0.4500 (36/80) ETA:20h:36m:57s 

Train: Epo[005/150] Iter[006/007] IterTime:[72.10s] LOSS: 1.0481 Batch ACC:0.3125 (5/16) Epo current ACC:0.4271 (41/96) ETA:20h:30m:31s 

Train: Epo[005/150] Iter[007/007] IterTime:[72.37s] LOSS: 0.9145 Batch ACC:0.5000 (8/16) Epo current ACC:0.4375 (49/112) ETA:20h:33m:50s 

Train: Epo[005/150] Epoch Summary Acc: 0.4375 (49/112)
tensor([[3.5607e-01, 6.4393e-01],
        [2.1922e-01, 7.8078e-01],
        [3.6522e-01, 6.3478e-01],
        [1.7776e-02, 9.8222e-01],
        [4.0096e-01, 5.9904e-01],
        [3.9059e-01, 6.0941e-01],
        [3.9160e-01, 6.0840e-01],
        [3.8001e-01, 6.1999e-01],
        [3.7546e-01, 6.2454e-01],
        [4.0341e-01, 5.9659e-01],
        [3.1600e-01, 6.8400e-01],
        [5.2722e-05, 9.9995e-01],
        [1.3926e-01, 8.6074e-01],
        [2.4274e-01, 7.5726e-01],
        [1.8038e-01, 8.1962e-01],
        [2.6887e-01, 7.3113e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:0, train loss:1.2200 ***********
tensor([[0.5124, 0.4876],
        [0.0027, 0.9973],
        [0.5086, 0.4914],
        [0.5284, 0.4716],
        [0.5267, 0.4733],
        [0.4251, 0.5749],
        [0.5270, 0.4730],
        [0.5089, 0.4911],
        [0.5233, 0.4767],
        [0.1106, 0.8894],
        [0.4585, 0.5415],
        [0.5145, 0.4855],
        [0.5000, 0.5000],
        [0.3275, 0.6725],
        [0.0272, 0.9728],
        [0.5314, 0.4686]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:1, train loss:1.3247 ***********
tensor([[0.1662, 0.8338],
        [0.5919, 0.4081],
        [0.0426, 0.9574],
        [0.5579, 0.4421],
        [0.6014, 0.3986],
        [0.5855, 0.4145],
        [0.6042, 0.3958],
        [0.5355, 0.4645],
        [0.4593, 0.5407],
        [0.2173, 0.7827],
        [0.6107, 0.3893],
        [0.6050, 0.3950],
        [0.5985, 0.4015],
        [0.5055, 0.4945],
        [0.6070, 0.3930],
        [0.0649, 0.9351]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:2, train loss:0.5774 ***********
tensor([[0.5779, 0.4221],
        [0.6952, 0.3048],
        [0.6968, 0.3032],
        [0.2888, 0.7112],
        [0.6472, 0.3528],
        [0.5056, 0.4944],
        [0.6878, 0.3122],
        [0.6957, 0.3043],
        [0.2353, 0.7647],
        [0.6722, 0.3278],
        [0.6126, 0.3874],
        [0.6720, 0.3280],
        [0.5983, 0.4017],
        [0.2120, 0.7880],
        [0.1918, 0.8082],
        [0.6549, 0.3451]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:3, train loss:0.6969 ***********
tensor([[0.5615, 0.4385],
        [0.6868, 0.3132],
        [0.7144, 0.2856],
        [0.7165, 0.2835],
        [0.5840, 0.4160],
        [0.6676, 0.3324],
        [0.4415, 0.5585],
        [0.7104, 0.2896],
        [0.7157, 0.2843],
        [0.6234, 0.3766],
        [0.6714, 0.3286],
        [0.5993, 0.4007],
        [0.7135, 0.2865],
        [0.7187, 0.2813],
        [0.7157, 0.2843],
        [0.6708, 0.3292]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:4, train loss:0.9969 ***********
Valid: Epo[005/150] Iter[001/004] LOSS: 22.9235 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (2/4)
Valid: Epo[005/150] Iter[002/004] LOSS: 1.5483 Batch ACC:0.7500 (3/4) Epo Current ACC:0.6250 (5/8)
Valid: Epo[005/150] Iter[003/004] LOSS: 25.0030 Batch ACC:0.7500 (3/4) Epo Current ACC:0.6667 (8/12)
Valid: Epo[005/150] Iter[004/004] LOSS: 64.9921 Batch ACC:0.2500 (1/4) Epo Current ACC:0.5625 (9/16)
Valid: Epo[005/150] Train Mean_Acc: 43.75% Valid Mean_Acc:56.25% OCEAN_ACC:0.5625 Epo Summary Acc:0.5625 (9/16)

Training: learning rate:0.0005
tensor([[1.0000e+00, 3.5486e-06],
        [1.0000e+00, 4.8023e-26],
        [1.0000e+00, 1.8844e-36],
        [1.0000e+00, 2.0330e-17]])
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:0, val loss:22.9235 ***********
tensor([[9.9793e-01, 2.0715e-03],
        [9.9999e-01, 5.5699e-06],
        [9.8646e-01, 1.3536e-02],
        [1.0000e+00, 0.0000e+00]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:1, val loss:1.5483 ***********
tensor([[1.0000e+00, 7.2544e-08],
        [1.0000e+00, 0.0000e+00],
        [9.8807e-01, 1.1928e-02],
        [1.0000e+00, 0.0000e+00]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:2, val loss:25.0030 ***********
tensor([[1.0000e+00, 2.3026e-09],
        [1.0000e+00, 0.0000e+00],
        [9.7662e-01, 2.3383e-02],
        [1.0000e+00, 0.0000e+00]])
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:3, val loss:64.9921 ***********
Train: Epo[006/150] Iter[001/007] IterTime:[74.49s] LOSS: 1.1756 Batch ACC:0.4375 (7/16) Epo current ACC:0.4375 (7/16) ETA:21h:8m:44s 

Train: Epo[006/150] Iter[002/007] IterTime:[73.60s] LOSS: 1.4514 Batch ACC:0.4375 (7/16) Epo current ACC:0.4375 (14/32) ETA:20h:52m:23s 

Train: Epo[006/150] Iter[003/007] IterTime:[74.15s] LOSS: 1.2565 Batch ACC:0.2500 (4/16) Epo current ACC:0.3750 (18/48) ETA:21h:0m:30s 

Train: Epo[006/150] Iter[004/007] IterTime:[72.85s] LOSS: 1.5771 Batch ACC:0.3125 (5/16) Epo current ACC:0.3594 (23/64) ETA:20h:37m:14s 

Train: Epo[006/150] Iter[005/007] IterTime:[72.51s] LOSS: 0.8850 Batch ACC:0.3750 (6/16) Epo current ACC:0.3625 (29/80) ETA:20h:30m:12s 

Train: Epo[006/150] Iter[006/007] IterTime:[73.29s] LOSS: 1.2799 Batch ACC:0.3750 (6/16) Epo current ACC:0.3646 (35/96) ETA:20h:42m:14s 

Train: Epo[006/150] Iter[007/007] IterTime:[72.31s] LOSS: 1.1201 Batch ACC:0.3125 (5/16) Epo current ACC:0.3571 (40/112) ETA:20h:24m:30s 

Train: Epo[006/150] Epoch Summary Acc: 0.3571428656578064 (40/112)
tensor([[6.2898e-01, 3.7102e-01],
        [8.4553e-01, 1.5447e-01],
        [6.8954e-01, 3.1046e-01],
        [6.2897e-01, 3.7103e-01],
        [6.3376e-01, 3.6624e-01],
        [6.3970e-01, 3.6030e-01],
        [6.2604e-01, 3.7396e-01],
        [7.4944e-01, 2.5056e-01],
        [6.1576e-01, 3.8424e-01],
        [6.3376e-01, 3.6624e-01],
        [6.2315e-01, 3.7685e-01],
        [6.3218e-01, 3.6782e-01],
        [6.4905e-01, 3.5095e-01],
        [6.2597e-01, 3.7403e-01],
        [6.2340e-01, 3.7660e-01],
        [9.9946e-01, 5.3759e-04]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:0, train loss:1.1756 ***********
tensor([[9.3459e-01, 6.5406e-02],
        [9.7052e-01, 2.9479e-02],
        [9.9921e-01, 7.8547e-04],
        [6.0964e-01, 3.9036e-01],
        [6.1647e-01, 3.8353e-01],
        [6.4941e-01, 3.5059e-01],
        [6.1309e-01, 3.8691e-01],
        [6.1158e-01, 3.8842e-01],
        [6.5453e-01, 3.4547e-01],
        [6.1345e-01, 3.8655e-01],
        [6.1115e-01, 3.8885e-01],
        [6.5119e-01, 3.4881e-01],
        [6.1168e-01, 3.8832e-01],
        [7.8478e-01, 2.1522e-01],
        [6.0647e-01, 3.9353e-01],
        [6.0134e-01, 3.9866e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:1, train loss:1.4514 ***********
tensor([[0.9824, 0.0176],
        [0.6013, 0.3987],
        [0.7661, 0.2339],
        [0.6923, 0.3077],
        [0.8681, 0.1319],
        [0.6037, 0.3963],
        [0.8871, 0.1129],
        [0.6081, 0.3919],
        [0.6069, 0.3931],
        [0.6023, 0.3977],
        [0.5934, 0.4066],
        [0.9987, 0.0013],
        [0.7316, 0.2684],
        [0.8507, 0.1493],
        [0.6061, 0.3939],
        [0.6997, 0.3003]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:2, train loss:1.2565 ***********
tensor([[9.9952e-01, 4.8365e-04],
        [5.5320e-01, 4.4680e-01],
        [5.5411e-01, 4.4589e-01],
        [9.5564e-01, 4.4358e-02],
        [5.4829e-01, 4.5171e-01],
        [5.5141e-01, 4.4859e-01],
        [5.4411e-01, 4.5589e-01],
        [5.5165e-01, 4.4835e-01],
        [8.5506e-01, 1.4494e-01],
        [5.4980e-01, 4.5020e-01],
        [5.7307e-01, 4.2693e-01],
        [5.4819e-01, 4.5181e-01],
        [5.5127e-01, 4.4873e-01],
        [9.9521e-01, 4.7861e-03],
        [5.4525e-01, 4.5475e-01],
        [6.1098e-01, 3.8902e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:3, train loss:1.5771 ***********
tensor([[0.5173, 0.4827],
        [0.5208, 0.4792],
        [0.5211, 0.4789],
        [0.5180, 0.4820],
        [0.5064, 0.4936],
        [0.7538, 0.2462],
        [0.8760, 0.1240],
        [0.5195, 0.4805],
        [0.7186, 0.2814],
        [0.5183, 0.4817],
        [0.6628, 0.3372],
        [0.9947, 0.0053],
        [0.5184, 0.4816],
        [0.9113, 0.0887],
        [0.9882, 0.0118],
        [0.5183, 0.4817]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:4, train loss:0.8850 ***********
Valid: Epo[006/150] Iter[001/004] LOSS: 1.0443 Batch ACC:0.7500 (3/4) Epo Current ACC:0.7500 (3/4)
Valid: Epo[006/150] Iter[002/004] LOSS: 23.2459 Batch ACC:0.5000 (2/4) Epo Current ACC:0.6250 (5/8)
Valid: Epo[006/150] Iter[003/004] LOSS: 0.4826 Batch ACC:0.7500 (3/4) Epo Current ACC:0.6667 (8/12)
Valid: Epo[006/150] Iter[004/004] LOSS: 15.6040 Batch ACC:0.7500 (3/4) Epo Current ACC:0.6875 (11/16)
Valid: Epo[006/150] Train Mean_Acc: 35.71% Valid Mean_Acc:68.75% OCEAN_ACC:0.6875 Epo Summary Acc:0.6875 (11/16)

Training: learning rate:0.0005
tensor([[9.9916e-01, 8.3897e-04],
        [9.9065e-01, 9.3496e-03],
        [5.8363e-01, 4.1637e-01],
        [9.7344e-01, 2.6556e-02]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:0, val loss:1.0443 ***********
tensor([[1.0000e+00, 1.0349e-35],
        [9.9999e-01, 7.0045e-06],
        [5.8669e-01, 4.1331e-01],
        [8.8607e-01, 1.1393e-01]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:1, val loss:23.2459 ***********
tensor([[5.8798e-01, 4.1202e-01],
        [1.0000e+00, 3.1418e-29],
        [5.9408e-01, 4.0592e-01],
        [5.8456e-01, 4.1544e-01]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:2, val loss:0.4826 ***********
tensor([[9.9951e-01, 4.9187e-04],
        [1.0000e+00, 4.8651e-11],
        [5.8149e-01, 4.1851e-01],
        [1.0000e+00, 1.8013e-40]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:3, val loss:15.6040 ***********
Train: Epo[007/150] Iter[001/007] IterTime:[76.54s] LOSS: 0.7763 Batch ACC:0.6250 (10/16) Epo current ACC:0.6250 (10/16) ETA:21h:34m:50s 

Train: Epo[007/150] Iter[002/007] IterTime:[75.47s] LOSS: 0.5973 Batch ACC:0.7500 (12/16) Epo current ACC:0.6875 (22/32) ETA:21h:15m:26s 

Train: Epo[007/150] Iter[003/007] IterTime:[75.00s] LOSS: 0.6799 Batch ACC:0.6250 (10/16) Epo current ACC:0.6667 (32/48) ETA:21h:6m:15s 

Train: Epo[007/150] Iter[004/007] IterTime:[73.05s] LOSS: 0.7129 Batch ACC:0.5625 (9/16) Epo current ACC:0.6406 (41/64) ETA:20h:32m:6s 

Train: Epo[007/150] Iter[005/007] IterTime:[72.86s] LOSS: 0.8484 Batch ACC:0.5625 (9/16) Epo current ACC:0.6250 (50/80) ETA:20h:27m:37s 

Train: Epo[007/150] Iter[006/007] IterTime:[72.70s] LOSS: 0.9859 Batch ACC:0.4375 (7/16) Epo current ACC:0.5938 (57/96) ETA:20h:23m:42s 

Train: Epo[007/150] Iter[007/007] IterTime:[72.98s] LOSS: 0.9035 Batch ACC:0.5625 (9/16) Epo current ACC:0.5893 (66/112) ETA:20h:27m:21s 

Train: Epo[007/150] Epoch Summary Acc: 0.5892857313156128 (66/112)
tensor([[0.3389, 0.6611],
        [0.3572, 0.6428],
        [0.3556, 0.6444],
        [0.6626, 0.3374],
        [0.4786, 0.5214],
        [0.3562, 0.6438],
        [0.3544, 0.6456],
        [0.4018, 0.5982],
        [0.3529, 0.6471],
        [0.3578, 0.6422],
        [0.3594, 0.6406],
        [0.3540, 0.6460],
        [0.3850, 0.6150],
        [0.8706, 0.1294],
        [0.8681, 0.1319],
        [0.3357, 0.6643]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:0, train loss:0.7763 ***********
tensor([[0.3315, 0.6685],
        [0.4297, 0.5703],
        [0.3459, 0.6541],
        [0.3448, 0.6552],
        [0.3452, 0.6548],
        [0.3490, 0.6510],
        [0.7265, 0.2735],
        [0.4814, 0.5186],
        [0.3360, 0.6640],
        [0.3450, 0.6550],
        [0.3347, 0.6653],
        [0.3497, 0.6503],
        [0.3549, 0.6451],
        [0.3347, 0.6653],
        [0.3238, 0.6762],
        [0.3458, 0.6542]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:1, train loss:0.5973 ***********
tensor([[0.2574, 0.7426],
        [0.2558, 0.7442],
        [0.2965, 0.7035],
        [0.2813, 0.7187],
        [0.2704, 0.7296],
        [0.2761, 0.7239],
        [0.2853, 0.7147],
        [0.2533, 0.7467],
        [0.2789, 0.7211],
        [0.2884, 0.7116],
        [0.2623, 0.7377],
        [0.2868, 0.7132],
        [0.2621, 0.7379],
        [0.2688, 0.7312],
        [0.2714, 0.7286],
        [0.2775, 0.7225]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:2, train loss:0.6799 ***********
tensor([[0.2685, 0.7315],
        [0.2709, 0.7291],
        [0.2491, 0.7509],
        [0.2746, 0.7254],
        [0.2753, 0.7247],
        [0.1144, 0.8856],
        [0.2609, 0.7391],
        [0.2589, 0.7411],
        [0.2823, 0.7177],
        [0.2613, 0.7387],
        [0.1337, 0.8663],
        [0.1565, 0.8435],
        [0.2740, 0.7260],
        [0.2739, 0.7261],
        [0.2619, 0.7381],
        [0.2706, 0.7294]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:3, train loss:0.7129 ***********
tensor([[0.2374, 0.7626],
        [0.2428, 0.7572],
        [0.1995, 0.8005],
        [0.2414, 0.7586],
        [0.0117, 0.9883],
        [0.1319, 0.8681],
        [0.2246, 0.7754],
        [0.2417, 0.7583],
        [0.2018, 0.7982],
        [0.2344, 0.7656],
        [0.2297, 0.7703],
        [0.2121, 0.7879],
        [0.0844, 0.9156],
        [0.2152, 0.7848],
        [0.1184, 0.8816],
        [0.2410, 0.7590]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:4, train loss:0.8484 ***********
Valid: Epo[007/150] Iter[001/004] LOSS: 4.4977 Batch ACC:0.2500 (1/4) Epo Current ACC:0.2500 (1/4)
Valid: Epo[007/150] Iter[002/004] LOSS: 0.8508 Batch ACC:0.5000 (2/4) Epo Current ACC:0.3750 (3/8)
Valid: Epo[007/150] Iter[003/004] LOSS: 20.7197 Batch ACC:0.7500 (3/4) Epo Current ACC:0.5000 (6/12)
Valid: Epo[007/150] Iter[004/004] LOSS: 23.2310 Batch ACC:0.2500 (1/4) Epo Current ACC:0.4375 (7/16)
Valid: Epo[007/150] Train Mean_Acc: 58.93% Valid Mean_Acc:43.75% OCEAN_ACC:0.4375 Epo Summary Acc:0.4375 (7/16)

Training: learning rate:0.0005
tensor([[2.9449e-30, 1.0000e+00],
        [2.4653e-01, 7.5347e-01],
        [1.1068e-04, 9.9989e-01],
        [5.6321e-04, 9.9944e-01]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:0, val loss:4.4977 ***********
tensor([[0.1847, 0.8153],
        [0.2451, 0.7549],
        [0.2437, 0.7563],
        [0.2218, 0.7782]])
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:1, val loss:0.8508 ***********
tensor([[2.5289e-01, 7.4711e-01],
        [4.6645e-04, 9.9953e-01],
        [8.1842e-29, 1.0000e+00],
        [2.2166e-01, 7.7834e-01]])
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:2, val loss:20.7197 ***********
tensor([[7.2825e-08, 1.0000e+00],
        [1.0791e-01, 8.9209e-01],
        [1.2686e-22, 1.0000e+00],
        [2.4376e-01, 7.5624e-01]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:3, val loss:23.2310 ***********
Train: Epo[008/150] Iter[001/007] IterTime:[77.31s] LOSS: 0.6366 Batch ACC:0.6875 (11/16) Epo current ACC:0.6875 (11/16) ETA:21h:38m:52s 

Train: Epo[008/150] Iter[002/007] IterTime:[74.09s] LOSS: 0.7891 Batch ACC:0.6250 (10/16) Epo current ACC:0.6562 (21/32) ETA:20h:43m:25s 

Train: Epo[008/150] Iter[003/007] IterTime:[75.17s] LOSS: 1.5511 Batch ACC:0.6250 (10/16) Epo current ACC:0.6458 (31/48) ETA:21h:0m:24s 

Train: Epo[008/150] Iter[004/007] IterTime:[77.93s] LOSS: 0.9433 Batch ACC:0.7500 (12/16) Epo current ACC:0.6719 (43/64) ETA:21h:45m:23s 

Train: Epo[008/150] Iter[005/007] IterTime:[73.51s] LOSS: 0.9107 Batch ACC:0.6875 (11/16) Epo current ACC:0.6750 (54/80) ETA:20h:29m:59s 

Train: Epo[008/150] Iter[006/007] IterTime:[73.54s] LOSS: 1.6275 Batch ACC:0.5000 (8/16) Epo current ACC:0.6458 (62/96) ETA:20h:29m:23s 

Train: Epo[008/150] Iter[007/007] IterTime:[74.95s] LOSS: 0.8644 Batch ACC:0.4375 (7/16) Epo current ACC:0.6161 (69/112) ETA:20h:51m:36s 

Train: Epo[008/150] Epoch Summary Acc: 0.6160714030265808 (69/112)
tensor([[1.9885e-01, 8.0115e-01],
        [1.9642e-01, 8.0358e-01],
        [1.9889e-01, 8.0111e-01],
        [1.2234e-01, 8.7766e-01],
        [1.9792e-01, 8.0208e-01],
        [6.7346e-05, 9.9993e-01],
        [1.9543e-01, 8.0457e-01],
        [2.0041e-01, 7.9959e-01],
        [1.9813e-01, 8.0187e-01],
        [1.9714e-01, 8.0286e-01],
        [1.6115e-01, 8.3885e-01],
        [3.0374e-04, 9.9970e-01],
        [1.9931e-01, 8.0069e-01],
        [1.9855e-01, 8.0145e-01],
        [1.9656e-01, 8.0344e-01],
        [1.9481e-01, 8.0519e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:0, train loss:0.6366 ***********
tensor([[2.2297e-01, 7.7703e-01],
        [2.6571e-03, 9.9734e-01],
        [2.2795e-01, 7.7205e-01],
        [2.2837e-01, 7.7163e-01],
        [2.2026e-01, 7.7974e-01],
        [2.2699e-01, 7.7301e-01],
        [2.2948e-01, 7.7052e-01],
        [8.1639e-06, 9.9999e-01],
        [2.2708e-01, 7.7292e-01],
        [2.1641e-01, 7.8359e-01],
        [1.8568e-01, 8.1432e-01],
        [2.2417e-01, 7.7583e-01],
        [1.3517e-01, 8.6483e-01],
        [1.9107e-01, 8.0893e-01],
        [6.4462e-02, 9.3554e-01],
        [2.2959e-01, 7.7041e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:1, train loss:0.7891 ***********
tensor([[2.0798e-01, 7.9202e-01],
        [2.0982e-01, 7.9018e-01],
        [2.0092e-01, 7.9908e-01],
        [2.4353e-01, 7.5647e-01],
        [2.4278e-01, 7.5722e-01],
        [2.3957e-01, 7.6043e-01],
        [1.9452e-01, 8.0548e-01],
        [2.1286e-01, 7.8714e-01],
        [2.5063e-01, 7.4937e-01],
        [2.4072e-01, 7.5928e-01],
        [8.8257e-05, 9.9991e-01],
        [1.6849e-01, 8.3151e-01],
        [3.1646e-02, 9.6835e-01],
        [1.8401e-01, 8.1599e-01],
        [2.3087e-01, 7.6913e-01],
        [5.3009e-04, 9.9947e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:2, train loss:1.5511 ***********
tensor([[1.5222e-01, 8.4778e-01],
        [1.2638e-01, 8.7362e-01],
        [1.2073e-02, 9.8793e-01],
        [2.7889e-04, 9.9972e-01],
        [1.3936e-01, 8.6064e-01],
        [1.9384e-01, 8.0616e-01],
        [1.3109e-01, 8.6891e-01],
        [2.2708e-01, 7.7292e-01],
        [7.1474e-02, 9.2853e-01],
        [2.1239e-01, 7.8761e-01],
        [2.2517e-01, 7.7483e-01],
        [2.2091e-01, 7.7909e-01],
        [2.2318e-01, 7.7682e-01],
        [1.7678e-05, 9.9998e-01],
        [2.1204e-01, 7.8796e-01],
        [1.9578e-01, 8.0422e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:3, train loss:0.9433 ***********
tensor([[2.5879e-01, 7.4121e-01],
        [2.4554e-01, 7.5446e-01],
        [2.5109e-01, 7.4891e-01],
        [2.5559e-01, 7.4441e-01],
        [2.2331e-01, 7.7669e-01],
        [2.5741e-01, 7.4259e-01],
        [6.9747e-03, 9.9303e-01],
        [2.5419e-01, 7.4581e-01],
        [1.7221e-01, 8.2779e-01],
        [2.5892e-01, 7.4108e-01],
        [6.3081e-02, 9.3692e-01],
        [2.5088e-01, 7.4912e-01],
        [3.0159e-07, 1.0000e+00],
        [2.3695e-01, 7.6305e-01],
        [2.5213e-01, 7.4787e-01],
        [2.5989e-01, 7.4011e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:4, train loss:0.9107 ***********
Valid: Epo[008/150] Iter[001/004] LOSS: 3.2748 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (2/4)
Valid: Epo[008/150] Iter[002/004] LOSS: 1.9334 Batch ACC:0.2500 (1/4) Epo Current ACC:0.3750 (3/8)
Valid: Epo[008/150] Iter[003/004] LOSS: 0.4047 Batch ACC:0.7500 (3/4) Epo Current ACC:0.5000 (6/12)
Valid: Epo[008/150] Iter[004/004] LOSS: 22.9949 Batch ACC:0.2500 (1/4) Epo Current ACC:0.4375 (7/16)
Valid: Epo[008/150] Train Mean_Acc: 61.61% Valid Mean_Acc:43.75% OCEAN_ACC:0.4375 Epo Summary Acc:0.4375 (7/16)

Training: learning rate:0.0005
tensor([[1.2853e-01, 8.7147e-01],
        [9.2993e-06, 9.9999e-01],
        [2.6056e-01, 7.3944e-01],
        [3.0445e-02, 9.6955e-01]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:0, val loss:3.2748 ***********
tensor([[0.0197, 0.9803],
        [0.1039, 0.8961],
        [0.1950, 0.8050],
        [0.2662, 0.7338]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:1, val loss:1.9334 ***********
tensor([[2.5906e-01, 7.4094e-01],
        [2.6864e-01, 7.3136e-01],
        [3.2615e-41, 1.0000e+00],
        [4.4790e-03, 9.9552e-01]])
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:2, val loss:0.4047 ***********
tensor([[1.0459e-26, 1.0000e+00],
        [2.6204e-01, 7.3796e-01],
        [2.8128e-05, 9.9997e-01],
        [2.2157e-01, 7.7843e-01]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:3, val loss:22.9949 ***********
Train: Epo[009/150] Iter[001/007] IterTime:[74.86s] LOSS: 0.7429 Batch ACC:0.5625 (9/16) Epo current ACC:0.5625 (9/16) ETA:20h:48m:53s 

Train: Epo[009/150] Iter[002/007] IterTime:[75.30s] LOSS: 0.6060 Batch ACC:0.6875 (11/16) Epo current ACC:0.6250 (20/32) ETA:20h:54m:55s 

Train: Epo[009/150] Iter[003/007] IterTime:[74.05s] LOSS: 0.6387 Batch ACC:0.5625 (9/16) Epo current ACC:0.6042 (29/48) ETA:20h:32m:57s 

Train: Epo[009/150] Iter[004/007] IterTime:[74.04s] LOSS: 0.5736 Batch ACC:0.6875 (11/16) Epo current ACC:0.6250 (40/64) ETA:20h:31m:36s 

Train: Epo[009/150] Iter[005/007] IterTime:[74.92s] LOSS: 0.5922 Batch ACC:0.6875 (11/16) Epo current ACC:0.6375 (51/80) ETA:20h:44m:50s 

Train: Epo[009/150] Iter[006/007] IterTime:[73.33s] LOSS: 1.7853 Batch ACC:0.6250 (10/16) Epo current ACC:0.6354 (61/96) ETA:20h:17m:19s 

Train: Epo[009/150] Iter[007/007] IterTime:[75.11s] LOSS: 0.7214 Batch ACC:0.3750 (6/16) Epo current ACC:0.5982 (67/112) ETA:20h:45m:33s 

Train: Epo[009/150] Epoch Summary Acc: 0.5982142686843872 (67/112)
tensor([[3.0895e-01, 6.9105e-01],
        [3.1607e-01, 6.8393e-01],
        [3.0828e-01, 6.9172e-01],
        [3.1340e-01, 6.8660e-01],
        [2.9230e-01, 7.0770e-01],
        [2.9905e-07, 1.0000e+00],
        [8.0246e-02, 9.1975e-01],
        [2.9533e-01, 7.0467e-01],
        [2.6354e-01, 7.3646e-01],
        [1.7371e-02, 9.8263e-01],
        [2.2571e-01, 7.7429e-01],
        [3.1261e-01, 6.8739e-01],
        [5.5207e-03, 9.9448e-01],
        [3.1561e-01, 6.8439e-01],
        [2.9855e-01, 7.0145e-01],
        [3.1759e-01, 6.8241e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:0, train loss:0.7429 ***********
tensor([[3.0137e-01, 6.9863e-01],
        [3.5632e-01, 6.4368e-01],
        [3.8637e-01, 6.1363e-01],
        [3.6843e-01, 6.3157e-01],
        [3.0546e-01, 6.9454e-01],
        [1.4958e-06, 1.0000e+00],
        [3.7073e-01, 6.2927e-01],
        [2.7068e-01, 7.2932e-01],
        [3.8460e-01, 6.1540e-01],
        [1.9100e-03, 9.9809e-01],
        [3.7544e-01, 6.2456e-01],
        [3.4525e-01, 6.5475e-01],
        [3.6709e-01, 6.3291e-01],
        [3.6072e-01, 6.3928e-01],
        [3.5522e-01, 6.4478e-01],
        [3.1083e-01, 6.8917e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:1, train loss:0.6060 ***********
tensor([[3.6189e-01, 6.3811e-01],
        [3.6311e-01, 6.3689e-01],
        [2.9154e-01, 7.0846e-01],
        [3.5774e-01, 6.4226e-01],
        [3.6208e-01, 6.3792e-01],
        [2.4215e-01, 7.5785e-01],
        [3.6277e-01, 6.3723e-01],
        [3.1541e-01, 6.8459e-01],
        [3.5954e-01, 6.4046e-01],
        [1.5811e-01, 8.4189e-01],
        [3.6279e-01, 6.3721e-01],
        [3.4275e-05, 9.9997e-01],
        [3.6475e-01, 6.3525e-01],
        [3.5405e-01, 6.4595e-01],
        [3.6143e-01, 6.3857e-01],
        [1.9187e-07, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:2, train loss:0.6387 ***********
tensor([[2.3904e-01, 7.6096e-01],
        [4.2021e-01, 5.7979e-01],
        [4.2134e-01, 5.7866e-01],
        [4.1454e-01, 5.8546e-01],
        [3.1984e-01, 6.8016e-01],
        [2.8573e-07, 1.0000e+00],
        [4.1222e-01, 5.8778e-01],
        [2.1467e-01, 7.8533e-01],
        [4.0541e-01, 5.9459e-01],
        [1.8487e-01, 8.1513e-01],
        [1.0225e-02, 9.8978e-01],
        [2.1047e-01, 7.8953e-01],
        [4.1619e-01, 5.8381e-01],
        [4.1749e-01, 5.8251e-01],
        [4.2203e-01, 5.7797e-01],
        [4.0893e-01, 5.9107e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:3, train loss:0.5736 ***********
tensor([[4.3500e-01, 5.6500e-01],
        [4.2734e-01, 5.7266e-01],
        [3.6596e-01, 6.3404e-01],
        [4.0748e-01, 5.9252e-01],
        [4.4536e-01, 5.5464e-01],
        [3.4622e-07, 1.0000e+00],
        [4.3839e-01, 5.6161e-01],
        [1.8502e-03, 9.9815e-01],
        [4.3059e-01, 5.6941e-01],
        [3.2291e-01, 6.7709e-01],
        [2.8882e-01, 7.1118e-01],
        [3.9426e-01, 6.0573e-01],
        [4.4495e-01, 5.5505e-01],
        [1.8713e-01, 8.1287e-01],
        [1.6948e-01, 8.3052e-01],
        [4.4043e-01, 5.5957e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:4, train loss:0.5922 ***********
Valid: Epo[009/150] Iter[001/004] LOSS: 21.0777 Batch ACC:0.2500 (1/4) Epo Current ACC:0.2500 (1/4)
Valid: Epo[009/150] Iter[002/004] LOSS: 16.1553 Batch ACC:0.2500 (1/4) Epo Current ACC:0.2500 (2/8)
Valid: Epo[009/150] Iter[003/004] LOSS: 0.6631 Batch ACC:0.7500 (3/4) Epo Current ACC:0.4167 (5/12)
Valid: Epo[009/150] Iter[004/004] LOSS: 0.5587 Batch ACC:0.5000 (2/4) Epo Current ACC:0.4375 (7/16)
Valid: Epo[009/150] Train Mean_Acc: 59.82% Valid Mean_Acc:43.75% OCEAN_ACC:0.4375 Epo Summary Acc:0.4375 (7/16)

Training: learning rate:0.0005
tensor([[6.9220e-29, 1.0000e+00],
        [1.2825e-32, 1.0000e+00],
        [4.6263e-01, 5.3737e-01],
        [3.2639e-01, 6.7361e-01]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:0, val loss:21.0777 ***********
tensor([[4.6777e-01, 5.3223e-01],
        [4.7044e-01, 5.2956e-01],
        [4.6741e-01, 5.3259e-01],
        [1.4537e-11, 1.0000e+00]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:1, val loss:16.1553 ***********
tensor([[4.7471e-01, 5.2529e-01],
        [4.6391e-01, 5.3609e-01],
        [6.5729e-06, 9.9999e-01],
        [2.5033e-01, 7.4967e-01]])
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:2, val loss:0.6631 ***********
tensor([[0.4644, 0.5356],
        [0.3682, 0.6318],
        [0.4294, 0.5706],
        [0.1504, 0.8496]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:3, val loss:0.5587 ***********
Train: Epo[010/150] Iter[001/007] IterTime:[75.78s] LOSS: 0.5989 Batch ACC:0.6250 (10/16) Epo current ACC:0.6250 (10/16) ETA:20h:55m:26s 

Train: Epo[010/150] Iter[002/007] IterTime:[75.91s] LOSS: 0.9805 Batch ACC:0.3125 (5/16) Epo current ACC:0.4688 (15/32) ETA:20h:56m:22s 

Train: Epo[010/150] Iter[003/007] IterTime:[74.17s] LOSS: 0.9199 Batch ACC:0.6250 (10/16) Epo current ACC:0.5208 (25/48) ETA:20h:26m:15s 

Train: Epo[010/150] Iter[004/007] IterTime:[75.81s] LOSS: 0.6292 Batch ACC:0.5000 (8/16) Epo current ACC:0.5156 (33/64) ETA:20h:52m:5s 

Train: Epo[010/150] Iter[005/007] IterTime:[74.84s] LOSS: 0.7558 Batch ACC:0.3125 (5/16) Epo current ACC:0.4750 (38/80) ETA:20h:34m:47s 

Train: Epo[010/150] Iter[006/007] IterTime:[72.94s] LOSS: 1.2764 Batch ACC:0.3125 (5/16) Epo current ACC:0.4479 (43/96) ETA:20h:2m:15s 

Train: Epo[010/150] Iter[007/007] IterTime:[75.64s] LOSS: 0.7148 Batch ACC:0.5000 (8/16) Epo current ACC:0.4554 (51/112) ETA:20h:45m:34s 

Train: Epo[010/150] Epoch Summary Acc: 0.4553571343421936 (51/112)
tensor([[5.2252e-01, 4.7748e-01],
        [9.7887e-08, 1.0000e+00],
        [2.6790e-01, 7.3210e-01],
        [4.8503e-01, 5.1497e-01],
        [5.0691e-01, 4.9309e-01],
        [4.6432e-01, 5.3568e-01],
        [5.1701e-01, 4.8299e-01],
        [5.1401e-01, 4.8599e-01],
        [3.4624e-01, 6.5376e-01],
        [5.1076e-01, 4.8924e-01],
        [4.6024e-01, 5.3976e-01],
        [2.9221e-01, 7.0779e-01],
        [5.3761e-01, 4.6239e-01],
        [4.9727e-01, 5.0273e-01],
        [5.3168e-01, 4.6832e-01],
        [5.3252e-01, 4.6748e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:0, train loss:0.5989 ***********
tensor([[5.4881e-02, 9.4512e-01],
        [5.5517e-01, 4.4483e-01],
        [5.6182e-01, 4.3818e-01],
        [5.5599e-01, 4.4401e-01],
        [5.5571e-01, 4.4429e-01],
        [5.3131e-01, 4.6869e-01],
        [5.5706e-01, 4.4294e-01],
        [5.4641e-01, 4.5359e-01],
        [5.3100e-01, 4.6900e-01],
        [3.5444e-07, 1.0000e+00],
        [5.2691e-02, 9.4731e-01],
        [5.2001e-01, 4.7999e-01],
        [5.5940e-01, 4.4060e-01],
        [3.5765e-01, 6.4235e-01],
        [4.1250e-01, 5.8750e-01],
        [5.6736e-01, 4.3264e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:1, train loss:0.9805 ***********
tensor([[2.4771e-03, 9.9752e-01],
        [5.7353e-01, 4.2647e-01],
        [4.9672e-01, 5.0328e-01],
        [5.7997e-01, 4.2003e-01],
        [5.8318e-01, 4.1682e-01],
        [5.4488e-01, 4.5512e-01],
        [3.8537e-01, 6.1463e-01],
        [1.1827e-01, 8.8173e-01],
        [5.7589e-01, 4.2411e-01],
        [5.5947e-01, 4.4053e-01],
        [5.7035e-01, 4.2965e-01],
        [2.0861e-06, 1.0000e+00],
        [4.5332e-01, 5.4668e-01],
        [5.3012e-01, 4.6988e-01],
        [5.7356e-01, 4.2644e-01],
        [5.8241e-01, 4.1759e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:2, train loss:0.9199 ***********
tensor([[5.7250e-01, 4.2750e-01],
        [5.9707e-01, 4.0293e-01],
        [5.4336e-01, 4.5664e-01],
        [5.8294e-01, 4.1706e-01],
        [6.0183e-01, 3.9817e-01],
        [1.5139e-05, 9.9998e-01],
        [5.8042e-01, 4.1958e-01],
        [5.3103e-01, 4.6897e-01],
        [2.3531e-01, 7.6469e-01],
        [5.9756e-01, 4.0244e-01],
        [6.0175e-01, 3.9825e-01],
        [5.9960e-01, 4.0040e-01],
        [5.8461e-01, 4.1539e-01],
        [5.6477e-01, 4.3523e-01],
        [5.8150e-01, 4.1850e-01],
        [4.1124e-04, 9.9959e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:3, train loss:0.6292 ***********
tensor([[1.0553e-05, 9.9999e-01],
        [5.9849e-01, 4.0151e-01],
        [5.4931e-01, 4.5069e-01],
        [5.9087e-01, 4.0913e-01],
        [5.9329e-01, 4.0671e-01],
        [4.6757e-01, 5.3243e-01],
        [1.7254e-01, 8.2746e-01],
        [4.4048e-01, 5.5952e-01],
        [5.8849e-01, 4.1151e-01],
        [6.0333e-01, 3.9667e-01],
        [5.9500e-01, 4.0500e-01],
        [6.0229e-01, 3.9771e-01],
        [5.8988e-01, 4.1012e-01],
        [6.0467e-01, 3.9533e-01],
        [1.1977e-02, 9.8802e-01],
        [6.0152e-01, 3.9848e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:4, train loss:0.7558 ***********
Valid: Epo[010/150] Iter[001/004] LOSS: 0.5980 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (2/4)
Valid: Epo[010/150] Iter[002/004] LOSS: 17.1145 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (4/8)
Valid: Epo[010/150] Iter[003/004] LOSS: 0.6216 Batch ACC:1.0000 (4/4) Epo Current ACC:0.6667 (8/12)
Valid: Epo[010/150] Iter[004/004] LOSS: 15.2946 Batch ACC:0.2500 (1/4) Epo Current ACC:0.5625 (9/16)
Valid: Epo[010/150] Train Mean_Acc: 45.54% Valid Mean_Acc:56.25% OCEAN_ACC:0.5625 Epo Summary Acc:0.5625 (9/16)

Training: learning rate:5e-05
tensor([[5.6207e-01, 4.3793e-01],
        [4.4496e-14, 1.0000e+00],
        [3.7246e-01, 6.2754e-01],
        [5.6320e-01, 4.3680e-01]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:0, val loss:0.5980 ***********
tensor([[1.0076e-01, 8.9924e-01],
        [4.2828e-01, 5.7172e-01],
        [2.4908e-15, 1.0000e+00],
        [4.9873e-01, 5.0127e-01]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:1, val loss:17.1145 ***********
tensor([[0.5080, 0.4920],
        [0.5643, 0.4357],
        [0.4825, 0.5175],
        [0.5608, 0.4392]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:2, val loss:0.6216 ***********
tensor([[7.0566e-02, 9.2943e-01],
        [1.0455e-08, 1.0000e+00],
        [3.3657e-01, 6.6343e-01],
        [5.6309e-01, 4.3691e-01]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:3, val loss:15.2946 ***********
Train: Epo[011/150] Iter[001/007] IterTime:[76.69s] LOSS: 0.6191 Batch ACC:0.5625 (9/16) Epo current ACC:0.5625 (9/16) ETA:21h:1m:33s 

Train: Epo[011/150] Iter[002/007] IterTime:[75.02s] LOSS: 0.5823 Batch ACC:0.6875 (11/16) Epo current ACC:0.6250 (20/32) ETA:20h:32m:50s 

Train: Epo[011/150] Iter[003/007] IterTime:[76.60s] LOSS: 0.6366 Batch ACC:0.5625 (9/16) Epo current ACC:0.6042 (29/48) ETA:20h:57m:31s 

Train: Epo[011/150] Iter[004/007] IterTime:[74.47s] LOSS: 1.1690 Batch ACC:0.5625 (9/16) Epo current ACC:0.5938 (38/64) ETA:20h:21m:13s 

Train: Epo[011/150] Iter[005/007] IterTime:[74.31s] LOSS: 0.6245 Batch ACC:0.5625 (9/16) Epo current ACC:0.5875 (47/80) ETA:20h:17m:30s 

Train: Epo[011/150] Iter[006/007] IterTime:[72.23s] LOSS: 0.7024 Batch ACC:0.2500 (4/16) Epo current ACC:0.5312 (51/96) ETA:19h:42m:14s 

Train: Epo[011/150] Iter[007/007] IterTime:[72.15s] LOSS: 0.6171 Batch ACC:0.6250 (10/16) Epo current ACC:0.5446 (61/112) ETA:19h:39m:35s 

Train: Epo[011/150] Epoch Summary Acc: 0.5446428656578064 (61/112)
tensor([[5.7726e-01, 4.2274e-01],
        [5.8662e-01, 4.1338e-01],
        [5.8481e-01, 4.1519e-01],
        [4.7647e-01, 5.2353e-01],
        [5.1034e-05, 9.9995e-01],
        [5.8133e-01, 4.1867e-01],
        [5.7809e-01, 4.2191e-01],
        [5.1550e-01, 4.8450e-01],
        [5.7459e-01, 4.2541e-01],
        [5.7822e-01, 4.2178e-01],
        [5.6153e-01, 4.3847e-01],
        [7.8191e-04, 9.9922e-01],
        [5.3951e-01, 4.6049e-01],
        [5.6243e-01, 4.3757e-01],
        [5.7941e-01, 4.2059e-01],
        [5.7090e-01, 4.2910e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:0, train loss:0.6191 ***********
tensor([[0.6392, 0.3608],
        [0.6340, 0.3660],
        [0.6371, 0.3629],
        [0.0075, 0.9925],
        [0.5078, 0.4922],
        [0.5806, 0.4194],
        [0.2159, 0.7841],
        [0.0499, 0.9501],
        [0.6320, 0.3680],
        [0.0122, 0.9878],
        [0.6370, 0.3630],
        [0.0626, 0.9374],
        [0.6387, 0.3613],
        [0.0037, 0.9963],
        [0.1420, 0.8580],
        [0.6240, 0.3760]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:1, train loss:0.5823 ***********
tensor([[4.7429e-01, 5.2571e-01],
        [5.6455e-01, 4.3545e-01],
        [1.3619e-06, 1.0000e+00],
        [5.4938e-01, 4.5062e-01],
        [5.6762e-01, 4.3238e-01],
        [5.1227e-01, 4.8773e-01],
        [5.6048e-01, 4.3952e-01],
        [5.5072e-01, 4.4928e-01],
        [5.5667e-01, 4.4333e-01],
        [5.4666e-01, 4.5334e-01],
        [5.6944e-01, 4.3056e-01],
        [4.5673e-01, 5.4327e-01],
        [5.2130e-01, 4.7870e-01],
        [5.3168e-01, 4.6832e-01],
        [5.6814e-01, 4.3186e-01],
        [5.7410e-01, 4.2590e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:2, train loss:0.6366 ***********
tensor([[4.5489e-01, 5.4511e-01],
        [6.0493e-01, 3.9507e-01],
        [5.8915e-01, 4.1085e-01],
        [5.9141e-01, 4.0859e-01],
        [7.8843e-02, 9.2116e-01],
        [1.1136e-02, 9.8886e-01],
        [5.9712e-01, 4.0288e-01],
        [6.0234e-01, 3.9766e-01],
        [6.0160e-01, 3.9840e-01],
        [6.0872e-01, 3.9128e-01],
        [5.9717e-01, 4.0283e-01],
        [6.9450e-05, 9.9993e-01],
        [5.7384e-01, 4.2616e-01],
        [4.1166e-01, 5.8834e-01],
        [5.1833e-01, 4.8167e-01],
        [1.6401e-01, 8.3599e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:3, train loss:1.1690 ***********
tensor([[5.7181e-01, 4.2819e-01],
        [5.6778e-01, 4.3222e-01],
        [6.3706e-06, 9.9999e-01],
        [5.7217e-01, 4.2783e-01],
        [5.5731e-01, 4.4269e-01],
        [4.1522e-01, 5.8478e-01],
        [5.5198e-01, 4.4802e-01],
        [4.9564e-01, 5.0436e-01],
        [5.7422e-01, 4.2578e-01],
        [5.7611e-01, 4.2389e-01],
        [5.8304e-01, 4.1696e-01],
        [7.2689e-02, 9.2731e-01],
        [5.6948e-01, 4.3052e-01],
        [5.5064e-01, 4.4936e-01],
        [3.1775e-01, 6.8225e-01],
        [5.6770e-01, 4.3230e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:4, train loss:0.6245 ***********
Valid: Epo[011/150] Iter[001/004] LOSS: 1.5996 Batch ACC:0.7500 (3/4) Epo Current ACC:0.7500 (3/4)
Valid: Epo[011/150] Iter[002/004] LOSS: 0.6839 Batch ACC:0.5000 (2/4) Epo Current ACC:0.6250 (5/8)
Valid: Epo[011/150] Iter[003/004] LOSS: 0.6298 Batch ACC:0.2500 (1/4) Epo Current ACC:0.5000 (6/12)
Valid: Epo[011/150] Iter[004/004] LOSS: 0.8504 Batch ACC:0.2500 (1/4) Epo Current ACC:0.4375 (7/16)
Valid: Epo[011/150] Train Mean_Acc: 54.46% Valid Mean_Acc:43.75% OCEAN_ACC:0.4375 Epo Summary Acc:0.4375 (7/16)

Training: learning rate:5e-05
tensor([[0.0078, 0.9922],
        [0.2957, 0.7043],
        [0.4633, 0.5367],
        [0.5667, 0.4333]])
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:0, val loss:1.5996 ***********
tensor([[0.5373, 0.4627],
        [0.5688, 0.4312],
        [0.4747, 0.5253],
        [0.5530, 0.4470]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:1, val loss:0.6839 ***********
tensor([[4.4934e-01, 5.5066e-01],
        [3.7201e-01, 6.2799e-01],
        [5.1826e-01, 4.8174e-01],
        [7.3448e-08, 1.0000e+00]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:2, val loss:0.6298 ***********
tensor([[0.5715, 0.4285],
        [0.5660, 0.4340],
        [0.3116, 0.6884],
        [0.5592, 0.4408]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:3, val loss:0.8504 ***********
Train: Epo[012/150] Iter[001/007] IterTime:[73.65s] LOSS: 0.5884 Batch ACC:0.5625 (9/16) Epo current ACC:0.5625 (9/16) ETA:20h:2m:55s 

Train: Epo[012/150] Iter[002/007] IterTime:[72.88s] LOSS: 1.1237 Batch ACC:0.3750 (6/16) Epo current ACC:0.4688 (15/32) ETA:19h:49m:5s 

Train: Epo[012/150] Iter[003/007] IterTime:[72.83s] LOSS: 0.6547 Batch ACC:0.4375 (7/16) Epo current ACC:0.4583 (22/48) ETA:19h:47m:7s 

Train: Epo[012/150] Iter[004/007] IterTime:[72.96s] LOSS: 0.5388 Batch ACC:0.5625 (9/16) Epo current ACC:0.4844 (31/64) ETA:19h:48m:5s 

Train: Epo[012/150] Iter[005/007] IterTime:[76.19s] LOSS: 1.0511 Batch ACC:0.2500 (4/16) Epo current ACC:0.4375 (35/80) ETA:20h:39m:24s 

Train: Epo[012/150] Iter[006/007] IterTime:[72.90s] LOSS: 0.7047 Batch ACC:0.6875 (11/16) Epo current ACC:0.4792 (46/96) ETA:19h:44m:41s 

Train: Epo[012/150] Iter[007/007] IterTime:[72.58s] LOSS: 0.7016 Batch ACC:0.5000 (8/16) Epo current ACC:0.4821 (54/112) ETA:19h:38m:8s 

Train: Epo[012/150] Epoch Summary Acc: 0.4821428656578064 (54/112)
tensor([[5.8191e-01, 4.1809e-01],
        [1.5721e-04, 9.9984e-01],
        [5.9263e-01, 4.0737e-01],
        [5.9765e-01, 4.0235e-01],
        [5.9128e-01, 4.0872e-01],
        [5.6255e-01, 4.3745e-01],
        [4.6194e-01, 5.3806e-01],
        [5.5412e-01, 4.4588e-01],
        [4.7756e-04, 9.9952e-01],
        [5.9242e-01, 4.0758e-01],
        [5.0877e-01, 4.9123e-01],
        [5.0476e-01, 4.9524e-01],
        [5.8679e-01, 4.1321e-01],
        [5.8860e-01, 4.1140e-01],
        [5.1907e-01, 4.8093e-01],
        [2.5777e-01, 7.4223e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:0, train loss:0.5884 ***********
tensor([[0.6069, 0.3931],
        [0.5485, 0.4515],
        [0.5469, 0.4531],
        [0.4974, 0.5026],
        [0.4344, 0.5656],
        [0.4089, 0.5911],
        [0.5914, 0.4086],
        [0.6069, 0.3931],
        [0.6075, 0.3925],
        [0.6108, 0.3892],
        [0.0579, 0.9421],
        [0.0049, 0.9951],
        [0.0356, 0.9644],
        [0.5859, 0.4141],
        [0.0020, 0.9980],
        [0.5781, 0.4219]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:1, train loss:1.1237 ***********
tensor([[5.6142e-01, 4.3858e-01],
        [5.5897e-01, 4.4103e-01],
        [1.5901e-06, 1.0000e+00],
        [4.0930e-01, 5.9070e-01],
        [3.2371e-01, 6.7629e-01],
        [4.4497e-01, 5.5503e-01],
        [5.5839e-01, 4.4161e-01],
        [5.6154e-01, 4.3846e-01],
        [5.5688e-01, 4.4312e-01],
        [3.2548e-01, 6.7452e-01],
        [5.6675e-01, 4.3325e-01],
        [4.5707e-01, 5.4293e-01],
        [5.3516e-01, 4.6484e-01],
        [5.6221e-01, 4.3779e-01],
        [5.2851e-01, 4.7149e-01],
        [5.6198e-01, 4.3802e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:2, train loss:0.6547 ***********
tensor([[5.5649e-01, 4.4351e-01],
        [4.9601e-01, 5.0399e-01],
        [8.3965e-05, 9.9992e-01],
        [1.2066e-01, 8.7934e-01],
        [5.5452e-01, 4.4548e-01],
        [3.5750e-02, 9.6425e-01],
        [5.4897e-01, 4.5103e-01],
        [7.3253e-02, 9.2675e-01],
        [5.3935e-01, 4.6065e-01],
        [5.5516e-01, 4.4484e-01],
        [5.4873e-01, 4.5127e-01],
        [5.4049e-01, 4.5951e-01],
        [5.4531e-01, 4.5469e-01],
        [5.1287e-01, 4.8713e-01],
        [5.5545e-01, 4.4455e-01],
        [5.5327e-01, 4.4673e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:3, train loss:0.5388 ***********
tensor([[5.4747e-01, 4.5253e-01],
        [5.5273e-01, 4.4727e-01],
        [5.6621e-01, 4.3379e-01],
        [5.6432e-01, 4.3568e-01],
        [5.5743e-01, 4.4257e-01],
        [5.2579e-01, 4.7421e-01],
        [3.2999e-01, 6.7001e-01],
        [4.8118e-01, 5.1882e-01],
        [1.6492e-04, 9.9984e-01],
        [5.0669e-01, 4.9331e-01],
        [5.6032e-01, 4.3968e-01],
        [5.6399e-01, 4.3601e-01],
        [5.2943e-01, 4.7057e-01],
        [5.3115e-01, 4.6885e-01],
        [5.2655e-01, 4.7345e-01],
        [1.3471e-03, 9.9865e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:4, train loss:1.0511 ***********
Valid: Epo[012/150] Iter[001/004] LOSS: 1.0536 Batch ACC:0.2500 (1/4) Epo Current ACC:0.2500 (1/4)
Valid: Epo[012/150] Iter[002/004] LOSS: 0.8538 Batch ACC:0.0000 (0/4) Epo Current ACC:0.1250 (1/8)
Valid: Epo[012/150] Iter[003/004] LOSS: 0.4057 Batch ACC:0.7500 (3/4) Epo Current ACC:0.3333 (4/12)
Valid: Epo[012/150] Iter[004/004] LOSS: 0.5027 Batch ACC:1.0000 (4/4) Epo Current ACC:0.5000 (8/16)
Valid: Epo[012/150] Train Mean_Acc: 48.21% Valid Mean_Acc:50.00% OCEAN_ACC:0.5 Epo Summary Acc:0.5 (8/16)

Training: learning rate:5e-05
tensor([[0.5625, 0.4375],
        [0.4973, 0.5027],
        [0.5208, 0.4792],
        [0.1305, 0.8695]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:0, val loss:1.0536 ***********
tensor([[0.3008, 0.6992],
        [0.4856, 0.5144],
        [0.4866, 0.5134],
        [0.5376, 0.4624]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:1, val loss:0.8538 ***********
tensor([[0.5357, 0.4643],
        [0.2204, 0.7796],
        [0.5215, 0.4785],
        [0.0125, 0.9875]])
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:2, val loss:0.4057 ***********
tensor([[0.2319, 0.7681],
        [0.5558, 0.4442],
        [0.5608, 0.4392],
        [0.5591, 0.4409]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:3, val loss:0.5027 ***********
Train: Epo[013/150] Iter[001/007] IterTime:[73.88s] LOSS: 0.5487 Batch ACC:0.6875 (11/16) Epo current ACC:0.6875 (11/16) ETA:19h:58m:2s 

Train: Epo[013/150] Iter[002/007] IterTime:[71.41s] LOSS: 0.5456 Batch ACC:0.7500 (12/16) Epo current ACC:0.7188 (23/32) ETA:19h:16m:45s 

Train: Epo[013/150] Iter[003/007] IterTime:[72.99s] LOSS: 0.5907 Batch ACC:0.5625 (9/16) Epo current ACC:0.6667 (32/48) ETA:19h:41m:17s 

Train: Epo[013/150] Iter[004/007] IterTime:[72.14s] LOSS: 0.5816 Batch ACC:0.4375 (7/16) Epo current ACC:0.6094 (39/64) ETA:19h:26m:15s 

Train: Epo[013/150] Iter[005/007] IterTime:[73.52s] LOSS: 0.7036 Batch ACC:0.6250 (10/16) Epo current ACC:0.6125 (49/80) ETA:19h:47m:21s 

Train: Epo[013/150] Iter[006/007] IterTime:[72.61s] LOSS: 0.6507 Batch ACC:0.5000 (8/16) Epo current ACC:0.5938 (57/96) ETA:19h:31m:28s 

Train: Epo[013/150] Iter[007/007] IterTime:[71.95s] LOSS: 1.4747 Batch ACC:0.5000 (8/16) Epo current ACC:0.5804 (65/112) ETA:19h:19m:35s 

Train: Epo[013/150] Epoch Summary Acc: 0.5803571343421936 (65/112)
tensor([[5.7683e-01, 4.2317e-01],
        [3.8007e-01, 6.1993e-01],
        [5.7328e-01, 4.2672e-01],
        [5.7410e-01, 4.2590e-01],
        [4.7974e-02, 9.5203e-01],
        [2.0914e-02, 9.7909e-01],
        [2.5034e-03, 9.9750e-01],
        [4.6090e-01, 5.3910e-01],
        [5.3920e-01, 4.6080e-01],
        [5.6608e-01, 4.3392e-01],
        [5.7236e-01, 4.2764e-01],
        [3.9165e-04, 9.9961e-01],
        [5.5190e-01, 4.4810e-01],
        [5.8063e-01, 4.1937e-01],
        [5.7028e-01, 4.2972e-01],
        [2.3331e-01, 7.6669e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:0, train loss:0.5487 ***********
tensor([[5.5784e-01, 4.4216e-01],
        [5.4165e-01, 4.5835e-01],
        [5.4231e-01, 4.5769e-01],
        [5.5743e-01, 4.4257e-01],
        [5.5407e-01, 4.4593e-01],
        [6.2642e-04, 9.9937e-01],
        [5.3443e-01, 4.6557e-01],
        [5.6042e-01, 4.3958e-01],
        [4.2323e-01, 5.7677e-01],
        [5.5533e-01, 4.4467e-01],
        [3.0797e-04, 9.9969e-01],
        [5.5803e-01, 4.4197e-01],
        [4.6557e-01, 5.3443e-01],
        [3.1145e-01, 6.8855e-01],
        [3.1334e-01, 6.8666e-01],
        [5.1772e-01, 4.8228e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:1, train loss:0.5456 ***********
tensor([[5.2516e-01, 4.7484e-01],
        [3.9062e-01, 6.0938e-01],
        [5.2156e-01, 4.7844e-01],
        [3.0316e-05, 9.9997e-01],
        [5.4841e-01, 4.5159e-01],
        [5.3457e-01, 4.6543e-01],
        [5.2664e-01, 4.7336e-01],
        [4.0905e-01, 5.9095e-01],
        [4.2842e-01, 5.7158e-01],
        [5.2940e-01, 4.7060e-01],
        [5.4681e-01, 4.5319e-01],
        [5.3498e-01, 4.6502e-01],
        [5.0929e-01, 4.9071e-01],
        [5.2431e-01, 4.7569e-01],
        [5.3217e-01, 4.6783e-01],
        [4.2231e-02, 9.5777e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:2, train loss:0.5907 ***********
tensor([[5.3008e-01, 4.6992e-01],
        [1.2779e-04, 9.9987e-01],
        [5.1693e-01, 4.8307e-01],
        [5.3701e-01, 4.6299e-01],
        [5.2250e-01, 4.7750e-01],
        [5.0371e-01, 4.9629e-01],
        [5.0771e-01, 4.9229e-01],
        [4.8160e-01, 5.1840e-01],
        [5.2558e-01, 4.7442e-01],
        [1.1995e-01, 8.8005e-01],
        [5.1294e-01, 4.8706e-01],
        [5.1192e-01, 4.8808e-01],
        [5.2579e-01, 4.7421e-01],
        [3.9776e-01, 6.0224e-01],
        [5.2578e-01, 4.7422e-01],
        [1.9638e-01, 8.0362e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:3, train loss:0.5816 ***********
tensor([[3.7276e-01, 6.2724e-01],
        [4.7798e-01, 5.2202e-01],
        [5.1662e-01, 4.8338e-01],
        [5.0921e-01, 4.9079e-01],
        [4.9603e-01, 5.0397e-01],
        [5.1046e-01, 4.8954e-01],
        [4.8599e-01, 5.1401e-01],
        [4.7021e-01, 5.2979e-01],
        [1.6003e-01, 8.3997e-01],
        [4.4590e-01, 5.5410e-01],
        [1.6198e-05, 9.9998e-01],
        [5.0221e-01, 4.9779e-01],
        [4.6057e-01, 5.3943e-01],
        [5.0544e-01, 4.9456e-01],
        [5.1102e-01, 4.8898e-01],
        [5.0995e-01, 4.9005e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:4, train loss:0.7036 ***********
Valid: Epo[013/150] Iter[001/004] LOSS: 0.5047 Batch ACC:1.0000 (4/4) Epo Current ACC:1.0000 (4/4)
Valid: Epo[013/150] Iter[002/004] LOSS: 1.4421 Batch ACC:0.5000 (2/4) Epo Current ACC:0.7500 (6/8)
Valid: Epo[013/150] Iter[003/004] LOSS: 0.7023 Batch ACC:0.5000 (2/4) Epo Current ACC:0.6667 (8/12)
Valid: Epo[013/150] Iter[004/004] LOSS: 1.3289 Batch ACC:0.2500 (1/4) Epo Current ACC:0.5625 (9/16)
Valid: Epo[013/150] Train Mean_Acc: 58.04% Valid Mean_Acc:56.25% OCEAN_ACC:0.5625 Epo Summary Acc:0.5625 (9/16)

Training: learning rate:5e-05
tensor([[0.5106, 0.4894],
        [0.0745, 0.9255],
        [0.5268, 0.4732],
        [0.5335, 0.4665]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:0, val loss:0.5047 ***********
tensor([[0.5164, 0.4836],
        [0.5270, 0.4730],
        [0.0239, 0.9761],
        [0.5355, 0.4645]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:1, val loss:1.4421 ***********
tensor([[0.4804, 0.5196],
        [0.4772, 0.5228],
        [0.5438, 0.4562],
        [0.5325, 0.4675]])
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:2, val loss:0.7023 ***********
tensor([[0.0549, 0.9451],
        [0.3655, 0.6345],
        [0.5385, 0.4615],
        [0.4690, 0.5310]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:3, val loss:1.3289 ***********
Train: Epo[014/150] Iter[001/007] IterTime:[75.54s] LOSS: 0.5435 Batch ACC:0.8125 (13/16) Epo current ACC:0.8125 (13/16) ETA:20h:16m:15s 

Train: Epo[014/150] Iter[002/007] IterTime:[73.93s] LOSS: 0.5980 Batch ACC:0.6250 (10/16) Epo current ACC:0.7188 (23/32) ETA:19h:49m:4s 

Train: Epo[014/150] Iter[003/007] IterTime:[74.41s] LOSS: 0.7479 Batch ACC:0.6875 (11/16) Epo current ACC:0.7083 (34/48) ETA:19h:55m:28s 

Train: Epo[014/150] Iter[004/007] IterTime:[73.80s] LOSS: 1.1245 Batch ACC:0.5625 (9/16) Epo current ACC:0.6719 (43/64) ETA:19h:44m:32s 

Train: Epo[014/150] Iter[005/007] IterTime:[72.76s] LOSS: 0.5855 Batch ACC:0.6875 (11/16) Epo current ACC:0.6750 (54/80) ETA:19h:26m:30s 

Train: Epo[014/150] Iter[006/007] IterTime:[72.08s] LOSS: 0.6374 Batch ACC:0.5000 (8/16) Epo current ACC:0.6458 (62/96) ETA:19h:14m:24s 

Train: Epo[014/150] Iter[007/007] IterTime:[71.80s] LOSS: 0.7053 Batch ACC:0.5625 (9/16) Epo current ACC:0.6339 (71/112) ETA:19h:8m:45s 

Train: Epo[014/150] Epoch Summary Acc: 0.6339285969734192 (71/112)
tensor([[4.9084e-01, 5.0916e-01],
        [5.2165e-01, 4.7835e-01],
        [4.5644e-01, 5.4356e-01],
        [5.0643e-01, 4.9357e-01],
        [4.6551e-01, 5.3449e-01],
        [2.4510e-01, 7.5490e-01],
        [4.6619e-01, 5.3381e-01],
        [1.8732e-04, 9.9981e-01],
        [5.2910e-01, 4.7090e-01],
        [5.2410e-01, 4.7590e-01],
        [5.1941e-01, 4.8059e-01],
        [1.4362e-02, 9.8564e-01],
        [5.2342e-01, 4.7658e-01],
        [5.0707e-01, 4.9293e-01],
        [2.9477e-01, 7.0523e-01],
        [5.0745e-01, 4.9255e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:0, train loss:0.5435 ***********
tensor([[0.3447, 0.6553],
        [0.0022, 0.9978],
        [0.5056, 0.4944],
        [0.4266, 0.5734],
        [0.5004, 0.4996],
        [0.4659, 0.5341],
        [0.0329, 0.9671],
        [0.4906, 0.5094],
        [0.5046, 0.4954],
        [0.4909, 0.5091],
        [0.5027, 0.4973],
        [0.0034, 0.9966],
        [0.4959, 0.5041],
        [0.3656, 0.6344],
        [0.3677, 0.6323],
        [0.5067, 0.4933]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:1, train loss:0.5980 ***********
tensor([[4.9191e-01, 5.0809e-01],
        [7.4414e-04, 9.9926e-01],
        [4.8982e-01, 5.1018e-01],
        [4.8911e-01, 5.1089e-01],
        [5.0337e-01, 4.9663e-01],
        [1.8684e-01, 8.1316e-01],
        [5.0250e-01, 4.9750e-01],
        [2.1532e-02, 9.7847e-01],
        [5.0957e-01, 4.9043e-01],
        [5.1020e-01, 4.8980e-01],
        [5.0834e-01, 4.9166e-01],
        [5.0419e-01, 4.9581e-01],
        [4.9251e-01, 5.0749e-01],
        [4.1371e-01, 5.8629e-01],
        [2.0807e-02, 9.7919e-01],
        [3.7901e-01, 6.2099e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:2, train loss:0.7479 ***********
tensor([[0.5014, 0.4986],
        [0.4905, 0.5095],
        [0.0023, 0.9977],
        [0.0408, 0.9592],
        [0.5086, 0.4914],
        [0.0392, 0.9608],
        [0.5086, 0.4914],
        [0.4904, 0.5096],
        [0.5162, 0.4838],
        [0.5166, 0.4834],
        [0.3304, 0.6696],
        [0.5112, 0.4888],
        [0.5197, 0.4803],
        [0.5212, 0.4788],
        [0.5115, 0.4885],
        [0.0036, 0.9964]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:3, train loss:1.1245 ***********
tensor([[4.8168e-01, 5.1832e-01],
        [4.8270e-01, 5.1730e-01],
        [4.9440e-01, 5.0560e-01],
        [4.8548e-01, 5.1452e-01],
        [4.7463e-01, 5.2537e-01],
        [4.8370e-01, 5.1630e-01],
        [4.8933e-01, 5.1067e-01],
        [4.8011e-01, 5.1989e-01],
        [4.6946e-01, 5.3054e-01],
        [4.8701e-01, 5.1299e-01],
        [9.1699e-06, 9.9999e-01],
        [1.8527e-02, 9.8147e-01],
        [4.0417e-01, 5.9583e-01],
        [4.8174e-01, 5.1826e-01],
        [4.8611e-01, 5.1389e-01],
        [4.8411e-01, 5.1589e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:4, train loss:0.5855 ***********
Valid: Epo[014/150] Iter[001/004] LOSS: 0.9294 Batch ACC:0.2500 (1/4) Epo Current ACC:0.2500 (1/4)
Valid: Epo[014/150] Iter[002/004] LOSS: 0.7215 Batch ACC:0.5000 (2/4) Epo Current ACC:0.3750 (3/8)
Valid: Epo[014/150] Iter[003/004] LOSS: 0.5435 Batch ACC:0.7500 (3/4) Epo Current ACC:0.5000 (6/12)
Valid: Epo[014/150] Iter[004/004] LOSS: 3.2795 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (8/16)
Valid: Epo[014/150] Train Mean_Acc: 63.39% Valid Mean_Acc:50.00% OCEAN_ACC:0.5 Epo Summary Acc:0.5 (8/16)

Training: learning rate:5e-05
tensor([[0.5096, 0.4904],
        [0.5147, 0.4853],
        [0.2052, 0.7948],
        [0.4786, 0.5214]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:0, val loss:0.9294 ***********
tensor([[0.4899, 0.5101],
        [0.4850, 0.5150],
        [0.4409, 0.5591],
        [0.5115, 0.4885]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:1, val loss:0.7215 ***********
tensor([[0.5101, 0.4899],
        [0.0577, 0.9423],
        [0.5079, 0.4921],
        [0.4658, 0.5342]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:2, val loss:0.5435 ***********
tensor([[5.0175e-01, 4.9825e-01],
        [7.9717e-06, 9.9999e-01],
        [1.1938e-01, 8.8062e-01],
        [4.2614e-01, 5.7386e-01]])
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:3, val loss:3.2795 ***********
Train: Epo[015/150] Iter[001/007] IterTime:[75.04s] LOSS: 0.6410 Batch ACC:0.6250 (10/16) Epo current ACC:0.6250 (10/16) ETA:19h:59m:23s 

Train: Epo[015/150] Iter[002/007] IterTime:[73.84s] LOSS: 0.4900 Batch ACC:0.8125 (13/16) Epo current ACC:0.7188 (23/32) ETA:19h:38m:55s 

Train: Epo[015/150] Iter[003/007] IterTime:[76.55s] LOSS: 0.5781 Batch ACC:0.8125 (13/16) Epo current ACC:0.7500 (36/48) ETA:20h:20m:54s 

Train: Epo[015/150] Iter[004/007] IterTime:[74.86s] LOSS: 0.5856 Batch ACC:0.6250 (10/16) Epo current ACC:0.7188 (46/64) ETA:19h:52m:46s 

Train: Epo[015/150] Iter[005/007] IterTime:[73.94s] LOSS: 0.6378 Batch ACC:0.5625 (9/16) Epo current ACC:0.6875 (55/80) ETA:19h:36m:53s 

Train: Epo[015/150] Iter[006/007] IterTime:[73.82s] LOSS: 0.9948 Batch ACC:0.4375 (7/16) Epo current ACC:0.6458 (62/96) ETA:19h:33m:40s 

Train: Epo[015/150] Iter[007/007] IterTime:[73.19s] LOSS: 0.9475 Batch ACC:0.5000 (8/16) Epo current ACC:0.6250 (70/112) ETA:19h:22m:33s 

Train: Epo[015/150] Epoch Summary Acc: 0.625 (70/112)
tensor([[4.8714e-01, 5.1286e-01],
        [4.8234e-01, 5.1766e-01],
        [4.8759e-01, 5.1241e-01],
        [4.8103e-01, 5.1897e-01],
        [4.9856e-01, 5.0144e-01],
        [4.8268e-01, 5.1732e-01],
        [4.5116e-01, 5.4884e-01],
        [2.6531e-01, 7.3469e-01],
        [4.9736e-01, 5.0264e-01],
        [4.9208e-01, 5.0792e-01],
        [4.9806e-01, 5.0194e-01],
        [3.9086e-05, 9.9996e-01],
        [4.0630e-01, 5.9370e-01],
        [4.9392e-01, 5.0608e-01],
        [4.5356e-01, 5.4644e-01],
        [5.0143e-01, 4.9857e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:0, train loss:0.6410 ***********
tensor([[2.8930e-04, 9.9971e-01],
        [4.2203e-01, 5.7797e-01],
        [4.9277e-01, 5.0723e-01],
        [3.1215e-01, 6.8785e-01],
        [4.8372e-01, 5.1628e-01],
        [4.9224e-01, 5.0776e-01],
        [6.0349e-02, 9.3965e-01],
        [4.4437e-01, 5.5563e-01],
        [4.6926e-01, 5.3074e-01],
        [4.9266e-01, 5.0734e-01],
        [4.6096e-01, 5.3904e-01],
        [4.2752e-03, 9.9572e-01],
        [4.3336e-01, 5.6664e-01],
        [3.3748e-01, 6.6252e-01],
        [4.2708e-01, 5.7292e-01],
        [4.2972e-01, 5.7028e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:1, train loss:0.4900 ***********
tensor([[4.6348e-01, 5.3652e-01],
        [9.8820e-02, 9.0118e-01],
        [4.8753e-01, 5.1247e-01],
        [3.5374e-01, 6.4626e-01],
        [4.7828e-01, 5.2172e-01],
        [4.3759e-01, 5.6241e-01],
        [4.7476e-01, 5.2524e-01],
        [4.8291e-01, 5.1709e-01],
        [4.8123e-01, 5.1877e-01],
        [4.3643e-01, 5.6357e-01],
        [4.0444e-01, 5.9556e-01],
        [4.4171e-01, 5.5829e-01],
        [4.5843e-01, 5.4157e-01],
        [3.3033e-05, 9.9997e-01],
        [4.8583e-01, 5.1417e-01],
        [4.8451e-01, 5.1548e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:2, train loss:0.5781 ***********
tensor([[4.9196e-01, 5.0804e-01],
        [8.4077e-02, 9.1592e-01],
        [4.6607e-01, 5.3393e-01],
        [4.9265e-01, 5.0735e-01],
        [4.8092e-01, 5.1908e-01],
        [1.1377e-04, 9.9989e-01],
        [4.8365e-01, 5.1635e-01],
        [4.9409e-01, 5.0591e-01],
        [4.7643e-01, 5.2357e-01],
        [4.8224e-01, 5.1776e-01],
        [4.4289e-01, 5.5711e-01],
        [4.6572e-01, 5.3428e-01],
        [4.4176e-01, 5.5824e-01],
        [4.8941e-01, 5.1059e-01],
        [2.7604e-01, 7.2396e-01],
        [4.8317e-01, 5.1683e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:3, train loss:0.5856 ***********
tensor([[4.8349e-01, 5.1651e-01],
        [4.7586e-01, 5.2414e-01],
        [6.9919e-04, 9.9930e-01],
        [4.4156e-01, 5.5844e-01],
        [1.8238e-01, 8.1762e-01],
        [3.2864e-01, 6.7136e-01],
        [1.1113e-01, 8.8887e-01],
        [4.7601e-01, 5.2399e-01],
        [4.6119e-01, 5.3881e-01],
        [4.8344e-01, 5.1656e-01],
        [4.9233e-01, 5.0767e-01],
        [4.7236e-01, 5.2764e-01],
        [3.5834e-01, 6.4166e-01],
        [2.0907e-02, 9.7909e-01],
        [4.4517e-01, 5.5483e-01],
        [4.8517e-01, 5.1483e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:4, train loss:0.6378 ***********
Valid: Epo[015/150] Iter[001/004] LOSS: 0.3720 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (2/4)
Valid: Epo[015/150] Iter[002/004] LOSS: 1.2553 Batch ACC:0.2500 (1/4) Epo Current ACC:0.3750 (3/8)
Valid: Epo[015/150] Iter[003/004] LOSS: 15.4135 Batch ACC:0.0000 (0/4) Epo Current ACC:0.2500 (3/12)
Valid: Epo[015/150] Iter[004/004] LOSS: 0.6675 Batch ACC:0.7500 (3/4) Epo Current ACC:0.3750 (6/16)
Valid: Epo[015/150] Train Mean_Acc: 62.50% Valid Mean_Acc:37.50% OCEAN_ACC:0.375 Epo Summary Acc:0.375 (6/16)

Training: learning rate:5e-05
tensor([[0.4833, 0.5167],
        [0.0356, 0.9644],
        [0.4871, 0.5129],
        [0.0053, 0.9947]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:0, val loss:0.3720 ***********
tensor([[0.0426, 0.9574],
        [0.4131, 0.5869],
        [0.4634, 0.5366],
        [0.1908, 0.8092]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:1, val loss:1.2553 ***********
tensor([[4.6997e-01, 5.3003e-01],
        [4.8658e-01, 5.1342e-01],
        [2.0495e-08, 1.0000e+00],
        [2.6522e-01, 7.3478e-01]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:2, val loss:15.4135 ***********
tensor([[0.4469, 0.5531],
        [0.4179, 0.5821],
        [0.4404, 0.5596],
        [0.4648, 0.5352]])
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:3, val loss:0.6675 ***********
Train: Epo[016/150] Iter[001/007] IterTime:[74.55s] LOSS: 0.5336 Batch ACC:0.8125 (13/16) Epo current ACC:0.8125 (13/16) ETA:19h:42m:49s 

Train: Epo[016/150] Iter[002/007] IterTime:[72.45s] LOSS: 0.6271 Batch ACC:0.5000 (8/16) Epo current ACC:0.6562 (21/32) ETA:19h:8m:19s 

Train: Epo[016/150] Iter[003/007] IterTime:[72.95s] LOSS: 0.5911 Batch ACC:0.5625 (9/16) Epo current ACC:0.6250 (30/48) ETA:19h:15m:6s 

Train: Epo[016/150] Iter[004/007] IterTime:[76.81s] LOSS: 0.8462 Batch ACC:0.5625 (9/16) Epo current ACC:0.6094 (39/64) ETA:20h:14m:49s 

Train: Epo[016/150] Iter[005/007] IterTime:[76.37s] LOSS: 0.6066 Batch ACC:0.6250 (10/16) Epo current ACC:0.6125 (49/80) ETA:20h:6m:34s 

Train: Epo[016/150] Iter[006/007] IterTime:[76.27s] LOSS: 0.6926 Batch ACC:0.5000 (8/16) Epo current ACC:0.5938 (57/96) ETA:20h:3m:46s 

Train: Epo[016/150] Iter[007/007] IterTime:[73.86s] LOSS: 0.5887 Batch ACC:0.8125 (13/16) Epo current ACC:0.6250 (70/112) ETA:19h:24m:35s 

Train: Epo[016/150] Epoch Summary Acc: 0.625 (70/112)
tensor([[4.8139e-01, 5.1861e-01],
        [4.7294e-01, 5.2706e-01],
        [4.7945e-01, 5.2055e-01],
        [3.2582e-01, 6.7418e-01],
        [7.5306e-02, 9.2469e-01],
        [6.2942e-05, 9.9994e-01],
        [3.9234e-01, 6.0766e-01],
        [2.4866e-01, 7.5134e-01],
        [4.8316e-01, 5.1684e-01],
        [4.7295e-01, 5.2705e-01],
        [4.0472e-01, 5.9528e-01],
        [4.8003e-01, 5.1997e-01],
        [4.7762e-01, 5.2238e-01],
        [4.7837e-01, 5.2163e-01],
        [4.7319e-01, 5.2681e-01],
        [4.8016e-01, 5.1984e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:0, train loss:0.5336 ***********
tensor([[4.4115e-01, 5.5885e-01],
        [3.8571e-01, 6.1429e-01],
        [7.1683e-02, 9.2832e-01],
        [4.3174e-01, 5.6826e-01],
        [4.4364e-01, 5.5636e-01],
        [3.3052e-01, 6.6948e-01],
        [4.4461e-01, 5.5539e-01],
        [4.3696e-01, 5.6304e-01],
        [3.9037e-01, 6.0963e-01],
        [1.5033e-05, 9.9998e-01],
        [4.3582e-01, 5.6418e-01],
        [4.4515e-01, 5.5485e-01],
        [4.3192e-01, 5.6808e-01],
        [4.5344e-01, 5.4656e-01],
        [4.0194e-01, 5.9806e-01],
        [4.4930e-01, 5.5070e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:1, train loss:0.6271 ***********
tensor([[4.5446e-01, 5.4554e-01],
        [4.4924e-01, 5.5076e-01],
        [1.0193e-01, 8.9807e-01],
        [4.5202e-01, 5.4798e-01],
        [4.2804e-01, 5.7196e-01],
        [4.3790e-01, 5.6210e-01],
        [4.3797e-01, 5.6203e-01],
        [9.6298e-05, 9.9990e-01],
        [5.5929e-03, 9.9441e-01],
        [4.4249e-01, 5.5751e-01],
        [4.2495e-01, 5.7505e-01],
        [3.4536e-01, 6.5464e-01],
        [2.2179e-01, 7.7821e-01],
        [2.5656e-01, 7.4344e-01],
        [4.2916e-01, 5.7084e-01],
        [4.5496e-01, 5.4504e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:2, train loss:0.5911 ***********
tensor([[4.5018e-01, 5.4982e-01],
        [3.7640e-01, 6.2360e-01],
        [8.7401e-02, 9.1260e-01],
        [3.7430e-01, 6.2570e-01],
        [3.1833e-01, 6.8167e-01],
        [3.5362e-01, 6.4638e-01],
        [2.0625e-01, 7.9375e-01],
        [4.5448e-01, 5.4552e-01],
        [4.4639e-01, 5.5361e-01],
        [4.5988e-01, 5.4012e-01],
        [5.6095e-02, 9.4391e-01],
        [4.5238e-01, 5.4762e-01],
        [4.3229e-01, 5.6771e-01],
        [2.5229e-01, 7.4771e-01],
        [2.9659e-04, 9.9970e-01],
        [4.3479e-01, 5.6521e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:3, train loss:0.8462 ***********
tensor([[4.3507e-01, 5.6493e-01],
        [4.6331e-01, 5.3669e-01],
        [4.2328e-01, 5.7672e-01],
        [4.4915e-01, 5.5085e-01],
        [3.7241e-01, 6.2759e-01],
        [4.4834e-01, 5.5166e-01],
        [4.5297e-01, 5.4703e-01],
        [5.2869e-03, 9.9471e-01],
        [4.2984e-01, 5.7016e-01],
        [4.4497e-01, 5.5503e-01],
        [3.9176e-01, 6.0824e-01],
        [4.6026e-01, 5.3974e-01],
        [2.6575e-04, 9.9973e-01],
        [2.8317e-01, 7.1683e-01],
        [4.1189e-01, 5.8811e-01],
        [4.4945e-01, 5.5055e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:4, train loss:0.6066 ***********
Valid: Epo[016/150] Iter[001/004] LOSS: 1.3958 Batch ACC:0.2500 (1/4) Epo Current ACC:0.2500 (1/4)
Valid: Epo[016/150] Iter[002/004] LOSS: 0.9476 Batch ACC:0.2500 (1/4) Epo Current ACC:0.2500 (2/8)
Valid: Epo[016/150] Iter[003/004] LOSS: 0.5977 Batch ACC:0.7500 (3/4) Epo Current ACC:0.4167 (5/12)
Valid: Epo[016/150] Iter[004/004] LOSS: 0.7623 Batch ACC:0.2500 (1/4) Epo Current ACC:0.3750 (6/16)
Valid: Epo[016/150] Train Mean_Acc: 62.50% Valid Mean_Acc:37.50% OCEAN_ACC:0.375 Epo Summary Acc:0.375 (6/16)

Training: learning rate:5e-05
tensor([[0.0337, 0.9663],
        [0.4638, 0.5362],
        [0.4426, 0.5574],
        [0.4696, 0.5304]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:0, val loss:1.3958 ***********
tensor([[0.4206, 0.5794],
        [0.4588, 0.5412],
        [0.4617, 0.5383],
        [0.2175, 0.7825]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:1, val loss:0.9476 ***********
tensor([[0.4336, 0.5664],
        [0.3705, 0.6295],
        [0.4170, 0.5830],
        [0.4247, 0.5753]])
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:2, val loss:0.5977 ***********
tensor([[0.4078, 0.5922],
        [0.4669, 0.5331],
        [0.4642, 0.5358],
        [0.4697, 0.5303]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:3, val loss:0.7623 ***********
Train: Epo[017/150] Iter[001/007] IterTime:[76.99s] LOSS: 0.5704 Batch ACC:0.7500 (12/16) Epo current ACC:0.7500 (12/16) ETA:20h:12m:31s 

Train: Epo[017/150] Iter[002/007] IterTime:[74.21s] LOSS: 0.6576 Batch ACC:0.6250 (10/16) Epo current ACC:0.6875 (22/32) ETA:19h:27m:35s 

Train: Epo[017/150] Iter[003/007] IterTime:[74.25s] LOSS: 0.5648 Batch ACC:0.6250 (10/16) Epo current ACC:0.6667 (32/48) ETA:19h:26m:56s 

Train: Epo[017/150] Iter[004/007] IterTime:[75.79s] LOSS: 1.0102 Batch ACC:0.5625 (9/16) Epo current ACC:0.6406 (41/64) ETA:19h:49m:51s 

Train: Epo[017/150] Iter[005/007] IterTime:[73.41s] LOSS: 1.2844 Batch ACC:0.5000 (8/16) Epo current ACC:0.6125 (49/80) ETA:19h:11m:19s 

Train: Epo[017/150] Iter[006/007] IterTime:[74.97s] LOSS: 0.7686 Batch ACC:0.6250 (10/16) Epo current ACC:0.6146 (59/96) ETA:19h:34m:28s 

Train: Epo[017/150] Iter[007/007] IterTime:[72.67s] LOSS: 0.5658 Batch ACC:0.6250 (10/16) Epo current ACC:0.6161 (69/112) ETA:18h:57m:14s 

Train: Epo[017/150] Epoch Summary Acc: 0.6160714030265808 (69/112)
tensor([[4.4324e-01, 5.5676e-01],
        [1.9718e-01, 8.0282e-01],
        [4.0403e-01, 5.9597e-01],
        [3.9354e-01, 6.0646e-01],
        [4.6406e-01, 5.3594e-01],
        [4.2681e-01, 5.7319e-01],
        [4.3245e-01, 5.6755e-01],
        [4.3292e-01, 5.6708e-01],
        [4.4483e-01, 5.5517e-01],
        [4.5495e-01, 5.4505e-01],
        [1.6386e-01, 8.3614e-01],
        [1.7319e-04, 9.9983e-01],
        [1.6721e-01, 8.3279e-01],
        [4.4246e-01, 5.5754e-01],
        [4.6411e-01, 5.3589e-01],
        [3.7129e-02, 9.6287e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:0, train loss:0.5704 ***********
tensor([[4.7003e-01, 5.2996e-01],
        [4.6593e-01, 5.3407e-01],
        [4.6338e-01, 5.3662e-01],
        [4.5296e-01, 5.4704e-01],
        [4.5500e-01, 5.4500e-01],
        [4.4256e-01, 5.5744e-01],
        [4.6158e-01, 5.3842e-01],
        [4.6143e-01, 5.3857e-01],
        [4.4681e-01, 5.5319e-01],
        [5.4386e-05, 9.9995e-01],
        [4.3754e-01, 5.6246e-01],
        [4.6174e-01, 5.3826e-01],
        [4.0436e-01, 5.9564e-01],
        [4.4100e-01, 5.5900e-01],
        [2.4387e-01, 7.5613e-01],
        [3.6614e-01, 6.3386e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:1, train loss:0.6576 ***********
tensor([[3.3484e-01, 6.6516e-01],
        [4.0728e-01, 5.9272e-01],
        [4.5395e-01, 5.4605e-01],
        [4.5459e-01, 5.4541e-01],
        [4.5030e-01, 5.4970e-01],
        [3.4485e-01, 6.5515e-01],
        [1.5813e-04, 9.9984e-01],
        [4.5277e-01, 5.4723e-01],
        [4.2785e-01, 5.7215e-01],
        [4.3808e-01, 5.6192e-01],
        [2.9521e-01, 7.0479e-01],
        [4.5098e-01, 5.4902e-01],
        [9.9385e-03, 9.9006e-01],
        [4.4379e-01, 5.5621e-01],
        [4.4158e-01, 5.5842e-01],
        [4.3875e-01, 5.6125e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:2, train loss:0.5648 ***********
tensor([[0.2633, 0.7367],
        [0.4651, 0.5349],
        [0.3184, 0.6816],
        [0.4519, 0.5481],
        [0.4539, 0.5461],
        [0.1689, 0.8311],
        [0.4590, 0.5410],
        [0.0019, 0.9981],
        [0.4576, 0.5424],
        [0.4543, 0.5457],
        [0.3406, 0.6594],
        [0.4537, 0.5463],
        [0.4234, 0.5766],
        [0.4646, 0.5354],
        [0.4527, 0.5473],
        [0.0571, 0.9429]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:3, train loss:1.0102 ***********
tensor([[4.3447e-01, 5.6553e-01],
        [4.4239e-01, 5.5761e-01],
        [4.4504e-01, 5.5496e-01],
        [4.3982e-01, 5.6018e-01],
        [4.2933e-04, 9.9957e-01],
        [4.4508e-01, 5.5492e-01],
        [4.1380e-01, 5.8620e-01],
        [4.3242e-01, 5.6758e-01],
        [4.5699e-01, 5.4301e-01],
        [4.5126e-01, 5.4874e-01],
        [4.4820e-01, 5.5180e-01],
        [2.8296e-01, 7.1704e-01],
        [4.4456e-01, 5.5544e-01],
        [1.8730e-01, 8.1270e-01],
        [6.6714e-02, 9.3329e-01],
        [4.4195e-01, 5.5805e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:4, train loss:1.2844 ***********
Valid: Epo[017/150] Iter[001/004] LOSS: 0.5583 Batch ACC:0.7500 (3/4) Epo Current ACC:0.7500 (3/4)
Valid: Epo[017/150] Iter[002/004] LOSS: 2.0314 Batch ACC:0.2500 (1/4) Epo Current ACC:0.5000 (4/8)
Valid: Epo[017/150] Iter[003/004] LOSS: 0.6796 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (6/12)
Valid: Epo[017/150] Iter[004/004] LOSS: 0.7540 Batch ACC:0.2500 (1/4) Epo Current ACC:0.4375 (7/16)
Valid: Epo[017/150] Train Mean_Acc: 61.61% Valid Mean_Acc:43.75% OCEAN_ACC:0.4375 Epo Summary Acc:0.4375 (7/16)

Training: learning rate:5e-05
tensor([[0.4363, 0.5637],
        [0.4577, 0.5423],
        [0.4584, 0.5416],
        [0.2351, 0.7649]])
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:0, val loss:0.5583 ***********
tensor([[0.2649, 0.7351],
        [0.4666, 0.5334],
        [0.0024, 0.9976],
        [0.0194, 0.9806]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:1, val loss:2.0314 ***********
tensor([[0.4361, 0.5639],
        [0.3525, 0.6475],
        [0.4544, 0.5456],
        [0.4282, 0.5718]])
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:2, val loss:0.6796 ***********
tensor([[0.4647, 0.5353],
        [0.4444, 0.5556],
        [0.4600, 0.5400],
        [0.4477, 0.5523]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:3, val loss:0.7540 ***********
Train: Epo[018/150] Iter[001/007] IterTime:[73.42s] LOSS: 0.6525 Batch ACC:0.7500 (12/16) Epo current ACC:0.7500 (12/16) ETA:19h:7m:50s 

Train: Epo[018/150] Iter[002/007] IterTime:[73.34s] LOSS: 0.6123 Batch ACC:0.5625 (9/16) Epo current ACC:0.6562 (21/32) ETA:19h:5m:19s 

Train: Epo[018/150] Iter[003/007] IterTime:[76.40s] LOSS: 0.5966 Batch ACC:0.6250 (10/16) Epo current ACC:0.6458 (31/48) ETA:19h:51m:46s 

Train: Epo[018/150] Iter[004/007] IterTime:[77.15s] LOSS: 0.7538 Batch ACC:0.6250 (10/16) Epo current ACC:0.6406 (41/64) ETA:20h:2m:19s 

Train: Epo[018/150] Iter[005/007] IterTime:[74.32s] LOSS: 1.2665 Batch ACC:0.5000 (8/16) Epo current ACC:0.6125 (49/80) ETA:19h:16m:56s 

Train: Epo[018/150] Iter[006/007] IterTime:[73.67s] LOSS: 0.5563 Batch ACC:0.8125 (13/16) Epo current ACC:0.6458 (62/96) ETA:19h:5m:36s 

Train: Epo[018/150] Iter[007/007] IterTime:[74.00s] LOSS: 0.6293 Batch ACC:0.5000 (8/16) Epo current ACC:0.6250 (70/112) ETA:19h:9m:24s 

Train: Epo[018/150] Epoch Summary Acc: 0.625 (70/112)
tensor([[4.4113e-01, 5.5887e-01],
        [4.4591e-01, 5.5409e-01],
        [4.5579e-01, 5.4421e-01],
        [3.1873e-01, 6.8127e-01],
        [4.3309e-01, 5.6691e-01],
        [4.3562e-01, 5.6438e-01],
        [4.5847e-01, 5.4153e-01],
        [4.5184e-01, 5.4816e-01],
        [4.1775e-01, 5.8225e-01],
        [4.3334e-01, 5.6666e-01],
        [3.9411e-01, 6.0589e-01],
        [4.5236e-01, 5.4764e-01],
        [1.2424e-01, 8.7576e-01],
        [2.0259e-04, 9.9980e-01],
        [1.1911e-01, 8.8089e-01],
        [4.5402e-01, 5.4598e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:0, train loss:0.6525 ***********
tensor([[4.2870e-01, 5.7130e-01],
        [4.1703e-01, 5.8297e-01],
        [1.9034e-01, 8.0966e-01],
        [4.0517e-01, 5.9483e-01],
        [3.5125e-01, 6.4875e-01],
        [4.0801e-01, 5.9199e-01],
        [4.0821e-01, 5.9179e-01],
        [4.3704e-01, 5.6296e-01],
        [4.4289e-01, 5.5711e-01],
        [4.1965e-01, 5.8035e-01],
        [3.6570e-01, 6.3430e-01],
        [4.3468e-01, 5.6532e-01],
        [6.0841e-05, 9.9994e-01],
        [4.3703e-01, 5.6297e-01],
        [4.3823e-01, 5.6177e-01],
        [4.3686e-01, 5.6314e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:1, train loss:0.6123 ***********
tensor([[4.5488e-01, 5.4512e-01],
        [4.4571e-01, 5.5429e-01],
        [2.3250e-01, 7.6750e-01],
        [4.3097e-01, 5.6903e-01],
        [4.3998e-01, 5.6002e-01],
        [4.4742e-01, 5.5258e-01],
        [4.4996e-01, 5.5004e-01],
        [4.2831e-01, 5.7169e-01],
        [4.1786e-01, 5.8214e-01],
        [8.4937e-05, 9.9992e-01],
        [4.5400e-01, 5.4600e-01],
        [4.4991e-01, 5.5009e-01],
        [4.3423e-01, 5.6577e-01],
        [4.3317e-01, 5.6683e-01],
        [3.9294e-01, 6.0706e-01],
        [4.4893e-01, 5.5107e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:2, train loss:0.5966 ***********
tensor([[4.0678e-01, 5.9322e-01],
        [4.3703e-01, 5.6297e-01],
        [4.3292e-01, 5.6708e-01],
        [3.9858e-01, 6.0142e-01],
        [4.4223e-01, 5.5777e-01],
        [4.2565e-01, 5.7435e-01],
        [3.8502e-01, 6.1498e-01],
        [4.3789e-01, 5.6211e-01],
        [1.8478e-01, 8.1522e-01],
        [4.3892e-01, 5.6108e-01],
        [1.2355e-01, 8.7645e-01],
        [4.2925e-01, 5.7075e-01],
        [6.7497e-04, 9.9933e-01],
        [2.5271e-02, 9.7473e-01],
        [4.2997e-01, 5.7003e-01],
        [4.2173e-01, 5.7827e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:3, train loss:0.7538 ***********
tensor([[0.4281, 0.5719],
        [0.3860, 0.6140],
        [0.0646, 0.9354],
        [0.4305, 0.5695],
        [0.2292, 0.7708],
        [0.4383, 0.5617],
        [0.4300, 0.5700],
        [0.0207, 0.9793],
        [0.4012, 0.5988],
        [0.4196, 0.5804],
        [0.4431, 0.5569],
        [0.4123, 0.5877],
        [0.0015, 0.9985],
        [0.1666, 0.8334],
        [0.4413, 0.5587],
        [0.4471, 0.5529]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:4, train loss:1.2665 ***********
Valid: Epo[018/150] Iter[001/004] LOSS: 0.8303 Batch ACC:0.0000 (0/4) Epo Current ACC:0.0000 (0/4)
Valid: Epo[018/150] Iter[002/004] LOSS: 0.6706 Batch ACC:0.2500 (1/4) Epo Current ACC:0.1250 (1/8)
Valid: Epo[018/150] Iter[003/004] LOSS: 0.4591 Batch ACC:0.7500 (3/4) Epo Current ACC:0.3333 (4/12)
Valid: Epo[018/150] Iter[004/004] LOSS: 0.8207 Batch ACC:0.7500 (3/4) Epo Current ACC:0.4375 (7/16)
Valid: Epo[018/150] Train Mean_Acc: 62.50% Valid Mean_Acc:43.75% OCEAN_ACC:0.4375 Epo Summary Acc:0.4375 (7/16)

Training: learning rate:5e-05
tensor([[0.4251, 0.5749],
        [0.4254, 0.5746],
        [0.4381, 0.5619],
        [0.4558, 0.5442]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:0, val loss:0.8303 ***********
tensor([[0.4178, 0.5822],
        [0.4568, 0.5432],
        [0.4490, 0.5510],
        [0.2019, 0.7981]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:1, val loss:0.6706 ***********
tensor([[0.4270, 0.5730],
        [0.4402, 0.5598],
        [0.0752, 0.9248],
        [0.2788, 0.7212]])
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:2, val loss:0.4591 ***********
tensor([[0.4546, 0.5454],
        [0.4482, 0.5518],
        [0.2294, 0.7706],
        [0.4566, 0.5434]])
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:3, val loss:0.8207 ***********
Train: Epo[019/150] Iter[001/007] IterTime:[74.14s] LOSS: 0.5893 Batch ACC:0.6875 (11/16) Epo current ACC:0.6875 (11/16) ETA:19h:10m:21s 

Train: Epo[019/150] Iter[002/007] IterTime:[72.24s] LOSS: 0.6802 Batch ACC:0.6250 (10/16) Epo current ACC:0.6562 (21/32) ETA:18h:39m:43s 

Train: Epo[019/150] Iter[003/007] IterTime:[72.39s] LOSS: 0.8596 Batch ACC:0.4375 (7/16) Epo current ACC:0.5833 (28/48) ETA:18h:40m:50s 

Train: Epo[019/150] Iter[004/007] IterTime:[72.52s] LOSS: 0.6348 Batch ACC:0.5000 (8/16) Epo current ACC:0.5625 (36/64) ETA:18h:41m:37s 

Train: Epo[019/150] Iter[005/007] IterTime:[72.97s] LOSS: 0.6312 Batch ACC:0.5000 (8/16) Epo current ACC:0.5500 (44/80) ETA:18h:47m:19s 

Train: Epo[019/150] Iter[006/007] IterTime:[71.51s] LOSS: 0.5403 Batch ACC:0.6875 (11/16) Epo current ACC:0.5729 (55/96) ETA:18h:23m:41s 

Train: Epo[019/150] Iter[007/007] IterTime:[72.18s] LOSS: 0.5687 Batch ACC:0.8125 (13/16) Epo current ACC:0.6071 (68/112) ETA:18h:32m:47s 

Train: Epo[019/150] Epoch Summary Acc: 0.6071428656578064 (68/112)
tensor([[4.4341e-01, 5.5659e-01],
        [4.0812e-01, 5.9188e-01],
        [4.4481e-01, 5.5519e-01],
        [4.3991e-01, 5.6009e-01],
        [4.1076e-01, 5.8924e-01],
        [4.4180e-01, 5.5820e-01],
        [4.5164e-01, 5.4836e-01],
        [4.4234e-01, 5.5766e-01],
        [4.4603e-01, 5.5397e-01],
        [3.5146e-01, 6.4854e-01],
        [4.4596e-01, 5.5404e-01],
        [3.3090e-01, 6.6910e-01],
        [4.4190e-01, 5.5810e-01],
        [4.3948e-01, 5.6052e-01],
        [4.4314e-01, 5.5686e-01],
        [7.5068e-05, 9.9992e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:0, train loss:0.5893 ***********
tensor([[4.3171e-01, 5.6829e-01],
        [3.1394e-01, 6.8606e-01],
        [4.2569e-01, 5.7431e-01],
        [4.3200e-01, 5.6800e-01],
        [4.2323e-01, 5.7677e-01],
        [1.9996e-01, 8.0004e-01],
        [4.3215e-01, 5.6785e-01],
        [4.3791e-01, 5.6209e-01],
        [4.1442e-01, 5.8558e-01],
        [4.4117e-01, 5.5883e-01],
        [4.3847e-01, 5.6153e-01],
        [2.6632e-01, 7.3368e-01],
        [2.6414e-04, 9.9974e-01],
        [4.1883e-01, 5.8117e-01],
        [4.4057e-01, 5.5943e-01],
        [4.3759e-01, 5.6241e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:1, train loss:0.6802 ***********
tensor([[0.3721, 0.6279],
        [0.4308, 0.5692],
        [0.0262, 0.9738],
        [0.4338, 0.5662],
        [0.1095, 0.8905],
        [0.3822, 0.6178],
        [0.2755, 0.7245],
        [0.0103, 0.9897],
        [0.4357, 0.5643],
        [0.2881, 0.7119],
        [0.1507, 0.8493],
        [0.4182, 0.5818],
        [0.4225, 0.5775],
        [0.4216, 0.5784],
        [0.3505, 0.6495],
        [0.0661, 0.9339]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:2, train loss:0.8596 ***********
tensor([[4.5298e-01, 5.4702e-01],
        [4.5182e-01, 5.4818e-01],
        [4.4840e-01, 5.5160e-01],
        [2.6730e-01, 7.3270e-01],
        [4.4205e-01, 5.5795e-01],
        [4.4449e-01, 5.5551e-01],
        [3.2682e-04, 9.9967e-01],
        [4.4190e-01, 5.5810e-01],
        [4.2931e-01, 5.7069e-01],
        [4.4436e-01, 5.5564e-01],
        [4.1824e-01, 5.8176e-01],
        [4.4762e-01, 5.5238e-01],
        [4.4320e-01, 5.5680e-01],
        [4.4450e-01, 5.5550e-01],
        [4.4906e-01, 5.5094e-01],
        [2.8700e-01, 7.1300e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:3, train loss:0.6348 ***********
tensor([[0.4328, 0.5672],
        [0.4100, 0.5900],
        [0.4389, 0.5611],
        [0.0027, 0.9973],
        [0.2355, 0.7645],
        [0.3968, 0.6032],
        [0.0247, 0.9753],
        [0.3866, 0.6134],
        [0.4334, 0.5666],
        [0.4282, 0.5718],
        [0.4117, 0.5883],
        [0.4052, 0.5948],
        [0.4213, 0.5787],
        [0.4005, 0.5995],
        [0.4339, 0.5661],
        [0.3894, 0.6106]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:4, train loss:0.6312 ***********
Valid: Epo[019/150] Iter[001/004] LOSS: 0.6951 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (2/4)
Valid: Epo[019/150] Iter[002/004] LOSS: 0.6644 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (4/8)
Valid: Epo[019/150] Iter[003/004] LOSS: 0.6853 Batch ACC:0.7500 (3/4) Epo Current ACC:0.5833 (7/12)
Valid: Epo[019/150] Iter[004/004] LOSS: 0.8370 Batch ACC:0.0000 (0/4) Epo Current ACC:0.4375 (7/16)
Valid: Epo[019/150] Train Mean_Acc: 60.71% Valid Mean_Acc:43.75% OCEAN_ACC:0.4375 Epo Summary Acc:0.4375 (7/16)

Training: learning rate:5e-05
tensor([[0.4378, 0.5622],
        [0.4425, 0.5575],
        [0.4173, 0.5827],
        [0.4278, 0.5722]])
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:0, val loss:0.6951 ***********
tensor([[0.3739, 0.6261],
        [0.4197, 0.5803],
        [0.4531, 0.5469],
        [0.4259, 0.5741]])
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:1, val loss:0.6644 ***********
tensor([[0.4541, 0.5459],
        [0.3225, 0.6775],
        [0.4485, 0.5515],
        [0.3163, 0.6837]])
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:2, val loss:0.6853 ***********
tensor([[0.4319, 0.5681],
        [0.4225, 0.5775],
        [0.4498, 0.5502],
        [0.4282, 0.5718]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:3, val loss:0.8370 ***********
Train: Epo[020/150] Iter[001/007] IterTime:[72.95s] LOSS: 0.6268 Batch ACC:0.6875 (11/16) Epo current ACC:0.6875 (11/16) ETA:18h:43m:28s 

Train: Epo[020/150] Iter[002/007] IterTime:[72.29s] LOSS: 0.5526 Batch ACC:0.7500 (12/16) Epo current ACC:0.7188 (23/32) ETA:18h:32m:0s 

Train: Epo[020/150] Iter[003/007] IterTime:[73.18s] LOSS: 0.9939 Batch ACC:0.5000 (8/16) Epo current ACC:0.6458 (31/48) ETA:18h:44m:28s 

Train: Epo[020/150] Iter[004/007] IterTime:[72.79s] LOSS: 0.9640 Batch ACC:0.5000 (8/16) Epo current ACC:0.6094 (39/64) ETA:18h:37m:20s 

Train: Epo[020/150] Iter[005/007] IterTime:[73.11s] LOSS: 1.1383 Batch ACC:0.5000 (8/16) Epo current ACC:0.5875 (47/80) ETA:18h:41m:4s 

Train: Epo[020/150] Iter[006/007] IterTime:[72.21s] LOSS: 0.5679 Batch ACC:0.6875 (11/16) Epo current ACC:0.6042 (58/96) ETA:18h:26m:0s 

Train: Epo[020/150] Iter[007/007] IterTime:[72.33s] LOSS: 0.5427 Batch ACC:0.8125 (13/16) Epo current ACC:0.6339 (71/112) ETA:18h:26m:40s 

Train: Epo[020/150] Epoch Summary Acc: 0.6339285969734192 (71/112)
tensor([[4.5296e-01, 5.4704e-01],
        [4.2963e-01, 5.7037e-01],
        [4.4877e-01, 5.5123e-01],
        [2.8705e-01, 7.1295e-01],
        [4.4500e-01, 5.5500e-01],
        [5.7339e-04, 9.9943e-01],
        [4.5085e-01, 5.4915e-01],
        [4.4525e-01, 5.5475e-01],
        [4.5536e-01, 5.4464e-01],
        [4.5289e-01, 5.4711e-01],
        [4.5373e-01, 5.4627e-01],
        [4.5191e-01, 5.4809e-01],
        [2.5081e-01, 7.4919e-01],
        [4.3258e-01, 5.6742e-01],
        [4.3054e-01, 5.6946e-01],
        [4.4961e-01, 5.5039e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:0, train loss:0.6268 ***********
tensor([[0.4272, 0.5728],
        [0.0084, 0.9916],
        [0.4347, 0.5653],
        [0.4409, 0.5591],
        [0.3866, 0.6134],
        [0.4328, 0.5672],
        [0.0013, 0.9987],
        [0.4338, 0.5662],
        [0.4010, 0.5990],
        [0.4300, 0.5700],
        [0.3709, 0.6291],
        [0.4219, 0.5781],
        [0.4372, 0.5628],
        [0.4121, 0.5879],
        [0.4334, 0.5666],
        [0.4076, 0.5924]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:1, train loss:0.5526 ***********
tensor([[0.4290, 0.5710],
        [0.4290, 0.5710],
        [0.4287, 0.5713],
        [0.3056, 0.6944],
        [0.4296, 0.5704],
        [0.1683, 0.8317],
        [0.3732, 0.6268],
        [0.2648, 0.7352],
        [0.3015, 0.6985],
        [0.0036, 0.9964],
        [0.4268, 0.5732],
        [0.4332, 0.5668],
        [0.4413, 0.5587],
        [0.0351, 0.9649],
        [0.4426, 0.5574],
        [0.4417, 0.5583]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:2, train loss:0.9939 ***********
tensor([[0.4189, 0.5811],
        [0.4101, 0.5899],
        [0.3753, 0.6247],
        [0.4146, 0.5854],
        [0.0055, 0.9945],
        [0.4290, 0.5710],
        [0.4083, 0.5917],
        [0.4202, 0.5798],
        [0.4161, 0.5839],
        [0.2337, 0.7663],
        [0.4136, 0.5864],
        [0.0278, 0.9722],
        [0.3795, 0.6205],
        [0.4253, 0.5747],
        [0.0653, 0.9347],
        [0.3720, 0.6280]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:3, train loss:0.9640 ***********
tensor([[0.0092, 0.9908],
        [0.4406, 0.5594],
        [0.4206, 0.5794],
        [0.4159, 0.5841],
        [0.3077, 0.6923],
        [0.4148, 0.5852],
        [0.4304, 0.5696],
        [0.4330, 0.5670],
        [0.3632, 0.6368],
        [0.0629, 0.9371],
        [0.4110, 0.5890],
        [0.2160, 0.7840],
        [0.0656, 0.9344],
        [0.2640, 0.7360],
        [0.4348, 0.5652],
        [0.4433, 0.5567]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:4, train loss:1.1383 ***********
Valid: Epo[020/150] Iter[001/004] LOSS: 0.6781 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (2/4)
Valid: Epo[020/150] Iter[002/004] LOSS: 0.8373 Batch ACC:0.2500 (1/4) Epo Current ACC:0.3750 (3/8)
Valid: Epo[020/150] Iter[003/004] LOSS: 0.6538 Batch ACC:0.2500 (1/4) Epo Current ACC:0.3333 (4/12)
Valid: Epo[020/150] Iter[004/004] LOSS: 1.3214 Batch ACC:0.2500 (1/4) Epo Current ACC:0.3125 (5/16)
Valid: Epo[020/150] Train Mean_Acc: 63.39% Valid Mean_Acc:31.25% OCEAN_ACC:0.3125 Epo Summary Acc:0.3125 (5/16)

Training: learning rate:5e-06
tensor([[0.4418, 0.5582],
        [0.4029, 0.5971],
        [0.4533, 0.5467],
        [0.4448, 0.5552]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:0, val loss:0.6781 ***********
tensor([[0.4569, 0.5431],
        [0.4496, 0.5504],
        [0.3267, 0.6733],
        [0.4401, 0.5599]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:1, val loss:0.8373 ***********
tensor([[0.4338, 0.5662],
        [0.1769, 0.8231],
        [0.4505, 0.5495],
        [0.4547, 0.5453]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:2, val loss:0.6538 ***********
tensor([[0.4515, 0.5485],
        [0.4329, 0.5671],
        [0.0438, 0.9562],
        [0.4516, 0.5484]])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:3, val loss:1.3214 ***********
Train: Epo[021/150] Iter[001/007] IterTime:[74.09s] LOSS: 0.7687 Batch ACC:0.6250 (10/16) Epo current ACC:0.6250 (10/16) ETA:18h:52m:21s 

Train: Epo[021/150] Iter[002/007] IterTime:[72.22s] LOSS: 0.4857 Batch ACC:0.8125 (13/16) Epo current ACC:0.7188 (23/32) ETA:18h:22m:33s 

Train: Epo[021/150] Iter[003/007] IterTime:[72.79s] LOSS: 0.8820 Batch ACC:0.5625 (9/16) Epo current ACC:0.6667 (32/48) ETA:18h:30m:1s 

Train: Epo[021/150] Iter[004/007] IterTime:[71.71s] LOSS: 0.7768 Batch ACC:0.3750 (6/16) Epo current ACC:0.5938 (38/64) ETA:18h:12m:25s 

Train: Epo[021/150] Iter[005/007] IterTime:[75.44s] LOSS: 0.6578 Batch ACC:0.6250 (10/16) Epo current ACC:0.6000 (48/80) ETA:19h:8m:0s 

Train: Epo[021/150] Iter[006/007] IterTime:[76.55s] LOSS: 0.6053 Batch ACC:0.6875 (11/16) Epo current ACC:0.6146 (59/96) ETA:19h:23m:35s 

Train: Epo[021/150] Iter[007/007] IterTime:[74.98s] LOSS: 0.5890 Batch ACC:0.7500 (12/16) Epo current ACC:0.6339 (71/112) ETA:18h:58m:29s 

Train: Epo[021/150] Epoch Summary Acc: 0.6339285969734192 (71/112)
tensor([[0.4447, 0.5553],
        [0.4330, 0.5670],
        [0.3914, 0.6086],
        [0.3806, 0.6194],
        [0.4173, 0.5827],
        [0.2862, 0.7138],
        [0.4302, 0.5698],
        [0.4178, 0.5822],
        [0.0347, 0.9653],
        [0.0182, 0.9818],
        [0.3717, 0.6283],
        [0.3413, 0.6587],
        [0.4244, 0.5756],
        [0.0189, 0.9811],
        [0.4356, 0.5644],
        [0.4416, 0.5584]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:0, train loss:0.7687 ***********
tensor([[0.3539, 0.6461],
        [0.0010, 0.9990],
        [0.4235, 0.5765],
        [0.4326, 0.5674],
        [0.2516, 0.7484],
        [0.2693, 0.7307],
        [0.4319, 0.5681],
        [0.4248, 0.5752],
        [0.1676, 0.8324],
        [0.4291, 0.5709],
        [0.4350, 0.5650],
        [0.4283, 0.5717],
        [0.4308, 0.5692],
        [0.4056, 0.5944],
        [0.1374, 0.8626],
        [0.4205, 0.5795]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:1, train loss:0.4857 ***********
tensor([[0.4268, 0.5732],
        [0.4406, 0.5594],
        [0.4211, 0.5789],
        [0.2505, 0.7495],
        [0.1013, 0.8987],
        [0.2701, 0.7299],
        [0.4395, 0.5605],
        [0.4074, 0.5926],
        [0.3019, 0.6981],
        [0.0602, 0.9398],
        [0.2384, 0.7616],
        [0.0088, 0.9912],
        [0.4265, 0.5735],
        [0.4222, 0.5778],
        [0.3922, 0.6078],
        [0.4097, 0.5903]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:2, train loss:0.8820 ***********
tensor([[0.0014, 0.9986],
        [0.4554, 0.5446],
        [0.4434, 0.5566],
        [0.4543, 0.5457],
        [0.4555, 0.5445],
        [0.3944, 0.6056],
        [0.4488, 0.5512],
        [0.3928, 0.6072],
        [0.4600, 0.5400],
        [0.4079, 0.5921],
        [0.4524, 0.5476],
        [0.4684, 0.5316],
        [0.4490, 0.5510],
        [0.4602, 0.5398],
        [0.0849, 0.9151],
        [0.4198, 0.5802]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:3, train loss:0.7768 ***********
tensor([[0.4295, 0.5705],
        [0.3752, 0.6248],
        [0.3536, 0.6464],
        [0.4449, 0.5551],
        [0.1343, 0.8657],
        [0.4439, 0.5561],
        [0.3544, 0.6456],
        [0.0034, 0.9966],
        [0.4478, 0.5522],
        [0.4516, 0.5484],
        [0.3869, 0.6131],
        [0.4158, 0.5842],
        [0.4456, 0.5544],
        [0.1519, 0.8481],
        [0.3943, 0.6057],
        [0.4481, 0.5519]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:4, train loss:0.6578 ***********
Valid: Epo[021/150] Iter[001/004] LOSS: 0.5314 Batch ACC:0.7500 (3/4) Epo Current ACC:0.7500 (3/4)
Valid: Epo[021/150] Iter[002/004] LOSS: 0.6379 Batch ACC:0.7500 (3/4) Epo Current ACC:0.7500 (6/8)
Valid: Epo[021/150] Iter[003/004] LOSS: 2.1198 Batch ACC:0.0000 (0/4) Epo Current ACC:0.5000 (6/12)
Valid: Epo[021/150] Iter[004/004] LOSS: 0.9675 Batch ACC:0.0000 (0/4) Epo Current ACC:0.3750 (6/16)
Valid: Epo[021/150] Train Mean_Acc: 63.39% Valid Mean_Acc:37.50% OCEAN_ACC:0.375 Epo Summary Acc:0.375 (6/16)

Training: learning rate:5e-06
tensor([[0.1417, 0.8583],
        [0.3683, 0.6317],
        [0.4462, 0.5538],
        [0.3976, 0.6024]])
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:0, val loss:0.5314 ***********
tensor([[0.4483, 0.5517],
        [0.4400, 0.5600],
        [0.4486, 0.5514],
        [0.4370, 0.5630]])
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:1, val loss:0.6379 ***********
tensor([[0.4071, 0.5929],
        [0.4439, 0.5561],
        [0.0026, 0.9974],
        [0.4499, 0.5501]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:2, val loss:2.1198 ***********
tensor([[0.3789, 0.6211],
        [0.4479, 0.5521],
        [0.3487, 0.6513],
        [0.3525, 0.6475]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:3, val loss:0.9675 ***********
Train: Epo[022/150] Iter[001/007] IterTime:[77.78s] LOSS: 0.5805 Batch ACC:0.6250 (10/16) Epo current ACC:0.6250 (10/16) ETA:19h:39m:41s 

Train: Epo[022/150] Iter[002/007] IterTime:[74.18s] LOSS: 0.6380 Batch ACC:0.5625 (9/16) Epo current ACC:0.5938 (19/32) ETA:18h:43m:53s 

Train: Epo[022/150] Iter[003/007] IterTime:[72.75s] LOSS: 0.6645 Batch ACC:0.7500 (12/16) Epo current ACC:0.6458 (31/48) ETA:18h:21m:1s 

Train: Epo[022/150] Iter[004/007] IterTime:[73.04s] LOSS: 0.8749 Batch ACC:0.6250 (10/16) Epo current ACC:0.6406 (41/64) ETA:18h:24m:8s 

Train: Epo[022/150] Iter[005/007] IterTime:[73.65s] LOSS: 0.5599 Batch ACC:0.6250 (10/16) Epo current ACC:0.6375 (51/80) ETA:18h:32m:3s 

Train: Epo[022/150] Iter[006/007] IterTime:[73.75s] LOSS: 1.0317 Batch ACC:0.4375 (7/16) Epo current ACC:0.6042 (58/96) ETA:18h:32m:26s 

Train: Epo[022/150] Iter[007/007] IterTime:[71.59s] LOSS: 0.5421 Batch ACC:0.7500 (12/16) Epo current ACC:0.6250 (70/112) ETA:17h:58m:33s 

Train: Epo[022/150] Epoch Summary Acc: 0.625 (70/112)
tensor([[4.3740e-01, 5.6260e-01],
        [1.0275e-01, 8.9725e-01],
        [4.3165e-01, 5.6835e-01],
        [2.4090e-01, 7.5910e-01],
        [4.3690e-01, 5.6310e-01],
        [4.2252e-01, 5.7748e-01],
        [4.3774e-01, 5.6226e-01],
        [4.3802e-01, 5.6198e-01],
        [4.3967e-01, 5.6033e-01],
        [6.2671e-04, 9.9937e-01],
        [4.3850e-01, 5.6150e-01],
        [4.4151e-01, 5.5849e-01],
        [4.2354e-01, 5.7646e-01],
        [3.7229e-01, 6.2771e-01],
        [4.3895e-01, 5.6105e-01],
        [4.4385e-01, 5.5615e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:0, train loss:0.5805 ***********
tensor([[0.1558, 0.8442],
        [0.4045, 0.5955],
        [0.4113, 0.5887],
        [0.4432, 0.5568],
        [0.4372, 0.5628],
        [0.4498, 0.5502],
        [0.4493, 0.5507],
        [0.4328, 0.5672],
        [0.4650, 0.5350],
        [0.4510, 0.5490],
        [0.4501, 0.5499],
        [0.4123, 0.5877],
        [0.3800, 0.6200],
        [0.0013, 0.9987],
        [0.4523, 0.5477],
        [0.4333, 0.5667]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.]])
*********** i:1, train loss:0.6380 ***********
tensor([[0.1530, 0.8470],
        [0.4417, 0.5583],
        [0.4332, 0.5668],
        [0.4074, 0.5926],
        [0.0046, 0.9954],
        [0.4349, 0.5651],
        [0.4056, 0.5944],
        [0.3545, 0.6455],
        [0.4426, 0.5574],
        [0.4301, 0.5699],
        [0.1857, 0.8143],
        [0.4317, 0.5683],
        [0.0593, 0.9407],
        [0.4216, 0.5784],
        [0.4310, 0.5690],
        [0.4386, 0.5614]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.]])
*********** i:2, train loss:0.6645 ***********
tensor([[0.4169, 0.5831],
        [0.4027, 0.5973],
        [0.4135, 0.5865],
        [0.4085, 0.5915],
        [0.3798, 0.6202],
        [0.3779, 0.6221],
        [0.0200, 0.9800],
        [0.4339, 0.5661],
        [0.4229, 0.5771],
        [0.4210, 0.5790],
        [0.4283, 0.5717],
        [0.0089, 0.9911],
        [0.3498, 0.6502],
        [0.4293, 0.5707],
        [0.4362, 0.5638],
        [0.4192, 0.5808]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:3, train loss:0.8749 ***********
tensor([[0.0224, 0.9776],
        [0.4384, 0.5616],
        [0.0086, 0.9914],
        [0.3864, 0.6136],
        [0.4166, 0.5834],
        [0.4240, 0.5760],
        [0.4139, 0.5861],
        [0.4336, 0.5664],
        [0.4122, 0.5878],
        [0.0640, 0.9360],
        [0.4298, 0.5702],
        [0.4286, 0.5714],
        [0.4180, 0.5820],
        [0.2835, 0.7165],
        [0.4284, 0.5716],
        [0.4265, 0.5735]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:4, train loss:0.5599 ***********
Valid: Epo[022/150] Iter[001/004] LOSS: 1.1328 Batch ACC:0.0000 (0/4) Epo Current ACC:0.0000 (0/4)
Valid: Epo[022/150] Iter[002/004] LOSS: 0.7346 Batch ACC:0.5000 (2/4) Epo Current ACC:0.2500 (2/8)
Valid: Epo[022/150] Iter[003/004] LOSS: 0.5678 Batch ACC:0.7500 (3/4) Epo Current ACC:0.4167 (5/12)
Valid: Epo[022/150] Iter[004/004] LOSS: 0.6368 Batch ACC:0.5000 (2/4) Epo Current ACC:0.4375 (7/16)
Valid: Epo[022/150] Train Mean_Acc: 62.50% Valid Mean_Acc:43.75% OCEAN_ACC:0.4375 Epo Summary Acc:0.4375 (7/16)

Training: learning rate:5e-06
tensor([[0.4437, 0.5563],
        [0.3995, 0.6005],
        [0.1361, 0.8639],
        [0.4461, 0.5539]])
tensor([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:0, val loss:1.1328 ***********
tensor([[0.4348, 0.5652],
        [0.4425, 0.5575],
        [0.3839, 0.6161],
        [0.4378, 0.5622]])
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:1, val loss:0.7346 ***********
tensor([[0.4378, 0.5622],
        [0.4482, 0.5518],
        [0.2464, 0.7536],
        [0.4414, 0.5586]])
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:2, val loss:0.5678 ***********
tensor([[0.4444, 0.5556],
        [0.4174, 0.5826],
        [0.3352, 0.6648],
        [0.3649, 0.6351]])
tensor([[1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:3, val loss:0.6368 ***********
Train: Epo[023/150] Iter[001/007] IterTime:[74.05s] LOSS: 0.6315 Batch ACC:0.5625 (9/16) Epo current ACC:0.5625 (9/16) ETA:18h:34m:27s 

Train: Epo[023/150] Iter[002/007] IterTime:[74.96s] LOSS: 0.6363 Batch ACC:0.5625 (9/16) Epo current ACC:0.5625 (18/32) ETA:18h:46m:50s 

Train: Epo[023/150] Iter[003/007] IterTime:[76.52s] LOSS: 0.5398 Batch ACC:0.8750 (14/16) Epo current ACC:0.6667 (32/48) ETA:19h:9m:7s 

Train: Epo[023/150] Iter[004/007] IterTime:[75.43s] LOSS: 0.6651 Batch ACC:0.5000 (8/16) Epo current ACC:0.6250 (40/64) ETA:18h:51m:29s 

Train: Epo[023/150] Iter[005/007] IterTime:[73.89s] LOSS: 0.7903 Batch ACC:0.6250 (10/16) Epo current ACC:0.6250 (50/80) ETA:18h:27m:2s 

Train: Epo[023/150] Iter[006/007] IterTime:[73.55s] LOSS: 0.7040 Batch ACC:0.5000 (8/16) Epo current ACC:0.6042 (58/96) ETA:18h:20m:44s 

Train: Epo[023/150] Iter[007/007] IterTime:[72.37s] LOSS: 0.8913 Batch ACC:0.6875 (11/16) Epo current ACC:0.6161 (69/112) ETA:18h:1m:56s 

Train: Epo[023/150] Epoch Summary Acc: 0.6160714030265808 (69/112)
tensor([[3.1546e-01, 6.8454e-01],
        [3.9057e-02, 9.6094e-01],
        [3.9248e-01, 6.0752e-01],
        [4.1771e-01, 5.8229e-01],
        [3.9011e-01, 6.0989e-01],
        [3.5291e-01, 6.4709e-01],
        [4.0716e-01, 5.9284e-01],
        [3.8294e-01, 6.1706e-01],
        [3.3988e-01, 6.6012e-01],
        [4.1958e-01, 5.8042e-01],
        [4.2636e-01, 5.7364e-01],
        [4.1577e-01, 5.8423e-01],
        [4.0497e-01, 5.9503e-01],
        [4.0562e-01, 5.9438e-01],
        [9.6130e-04, 9.9904e-01],
        [4.1755e-01, 5.8245e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.]])
*********** i:0, train loss:0.6315 ***********
tensor([[4.4482e-01, 5.5518e-01],
        [3.4796e-01, 6.5204e-01],
        [4.3661e-01, 5.6339e-01],
        [4.4613e-01, 5.5387e-01],
        [4.4035e-01, 5.5965e-01],
        [4.2207e-01, 5.7793e-01],
        [4.3896e-01, 5.6104e-01],
        [4.3201e-01, 5.6799e-01],
        [4.4722e-01, 5.5278e-01],
        [4.0470e-01, 5.9530e-01],
        [4.4026e-01, 5.5974e-01],
        [3.8844e-01, 6.1156e-01],
        [4.2479e-01, 5.7521e-01],
        [4.3286e-01, 5.6714e-01],
        [4.0602e-04, 9.9959e-01],
        [3.9518e-01, 6.0482e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:1, train loss:0.6363 ***********
tensor([[0.4578, 0.5422],
        [0.4497, 0.5503],
        [0.4597, 0.5403],
        [0.4118, 0.5882],
        [0.3599, 0.6401],
        [0.3583, 0.6417],
        [0.3713, 0.6287],
        [0.4619, 0.5381],
        [0.4513, 0.5487],
        [0.4495, 0.5505],
        [0.4551, 0.5449],
        [0.4109, 0.5891],
        [0.0983, 0.9017],
        [0.4487, 0.5513],
        [0.0037, 0.9963],
        [0.4371, 0.5629]], grad_fn=<SoftmaxBackward0>)
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:2, train loss:0.5398 ***********
tensor([[0.3990, 0.6010],
        [0.4511, 0.5489],
        [0.4421, 0.5579],
        [0.3989, 0.6011],
        [0.0213, 0.9787],
        [0.4316, 0.5684],
        [0.4369, 0.5631],
        [0.4213, 0.5787],
        [0.4155, 0.5845],
        [0.2098, 0.7902],
        [0.4334, 0.5666],
        [0.4263, 0.5737],
        [0.4466, 0.5534],
        [0.4449, 0.5551],
        [0.0080, 0.9920],
        [0.4502, 0.5498]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:3, train loss:0.6651 ***********
tensor([[0.4299, 0.5701],
        [0.0152, 0.9848],
        [0.2139, 0.7861],
        [0.1833, 0.8167],
        [0.4283, 0.5717],
        [0.4259, 0.5741],
        [0.4252, 0.5748],
        [0.0189, 0.9811],
        [0.4251, 0.5749],
        [0.4289, 0.5711],
        [0.4434, 0.5566],
        [0.4316, 0.5684],
        [0.4433, 0.5567],
        [0.4423, 0.5577],
        [0.4356, 0.5644],
        [0.4381, 0.5619]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:4, train loss:0.7903 ***********
Valid: Epo[023/150] Iter[001/004] LOSS: 0.6363 Batch ACC:0.5000 (2/4) Epo Current ACC:0.5000 (2/4)
Valid: Epo[023/150] Iter[002/004] LOSS: 0.8278 Batch ACC:0.2500 (1/4) Epo Current ACC:0.3750 (3/8)
Valid: Epo[023/150] Iter[003/004] LOSS: 1.2091 Batch ACC:0.5000 (2/4) Epo Current ACC:0.4167 (5/12)
Valid: Epo[023/150] Iter[004/004] LOSS: 0.7251 Batch ACC:0.5000 (2/4) Epo Current ACC:0.4375 (7/16)
Valid: Epo[023/150] Train Mean_Acc: 61.61% Valid Mean_Acc:43.75% OCEAN_ACC:0.4375 Epo Summary Acc:0.4375 (7/16)

Training: learning rate:5e-06
tensor([[0.2732, 0.7268],
        [0.4430, 0.5570],
        [0.4418, 0.5582],
        [0.4386, 0.5614]])
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]])
*********** i:0, val loss:0.6363 ***********
tensor([[0.4429, 0.5571],
        [0.4312, 0.5688],
        [0.3494, 0.6506],
        [0.4344, 0.5656]])
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.]])
*********** i:1, val loss:0.8278 ***********
tensor([[3.2074e-02, 9.6793e-01],
        [4.3514e-01, 5.6486e-01],
        [1.2980e-10, 1.0000e+00],
        [4.3794e-01, 5.6206e-01]])
tensor([[1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:2, val loss:1.2091 ***********
tensor([[0.4201, 0.5799],
        [0.4248, 0.5752],
        [0.4245, 0.5755],
        [0.3880, 0.6120]])
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:3, val loss:0.7251 ***********
Train: Epo[024/150] Iter[001/007] IterTime:[74.04s] LOSS: 0.6557 Batch ACC:0.5000 (8/16) Epo current ACC:0.5000 (8/16) ETA:18h:25m:43s 

Train: Epo[024/150] Iter[002/007] IterTime:[74.66s] LOSS: 0.7885 Batch ACC:0.8125 (13/16) Epo current ACC:0.6562 (21/32) ETA:18h:33m:40s 

Train: Epo[024/150] Iter[003/007] IterTime:[74.87s] LOSS: 0.5809 Batch ACC:0.5625 (9/16) Epo current ACC:0.6250 (30/48) ETA:18h:35m:36s 

Train: Epo[024/150] Iter[004/007] IterTime:[73.41s] LOSS: 0.8813 Batch ACC:0.5625 (9/16) Epo current ACC:0.6094 (39/64) ETA:18h:12m:32s 

tensor([[4.1267e-01, 5.8733e-01],
        [4.4300e-01, 5.5700e-01],
        [4.5063e-01, 5.4937e-01],
        [4.4620e-01, 5.5380e-01],
        [3.7432e-04, 9.9963e-01],
        [4.4858e-01, 5.5142e-01],
        [4.1158e-01, 5.8842e-01],
        [4.1796e-01, 5.8204e-01],
        [3.9286e-01, 6.0714e-01],
        [3.6355e-01, 6.3645e-01],
        [4.4463e-01, 5.5537e-01],
        [3.5091e-01, 6.4909e-01],
        [4.4007e-01, 5.5993e-01],
        [4.4514e-01, 5.5486e-01],
        [4.3503e-01, 5.6497e-01],
        [4.4181e-01, 5.5819e-01]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:0, train loss:0.6557 ***********
tensor([[0.2846, 0.7154],
        [0.4206, 0.5794],
        [0.4091, 0.5909],
        [0.4362, 0.5638],
        [0.4220, 0.5780],
        [0.4381, 0.5619],
        [0.3236, 0.6764],
        [0.4298, 0.5702],
        [0.0050, 0.9950],
        [0.4265, 0.5735],
        [0.4368, 0.5632],
        [0.0239, 0.9761],
        [0.4167, 0.5833],
        [0.1562, 0.8438],
        [0.1857, 0.8143],
        [0.4341, 0.5659]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.]])
*********** i:1, train loss:0.7885 ***********
tensor([[0.2150, 0.7850],
        [0.3411, 0.6589],
        [0.0501, 0.9499],
        [0.4358, 0.5642],
        [0.0167, 0.9833],
        [0.0642, 0.9358],
        [0.4018, 0.5982],
        [0.4224, 0.5776],
        [0.4396, 0.5604],
        [0.4200, 0.5800],
        [0.3222, 0.6778],
        [0.4385, 0.5615],
        [0.4208, 0.5792],
        [0.4238, 0.5762],
        [0.4308, 0.5692],
        [0.4221, 0.5779]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
*********** i:2, train loss:0.5809 ***********
tensor([[0.4477, 0.5523],
        [0.0069, 0.9931],
        [0.4143, 0.5857],
        [0.3916, 0.6084],
        [0.3469, 0.6531],
        [0.4397, 0.5603],
        [0.1838, 0.8162],
        [0.4438, 0.5562],
        [0.0948, 0.9052],
        [0.4392, 0.5608],
        [0.4165, 0.5835],
        [0.4456, 0.5544],
        [0.3880, 0.6120],
        [0.2152, 0.7848],
        [0.4241, 0.5759],
        [0.4353, 0.5647]], grad_fn=<SoftmaxBackward0>)
tensor([[0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])
*********** i:3, train loss:0.8813 ***********
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:          Train Mean_Acc ‚ñá‚ñÅ‚ñÑ‚ñá‚ñÉ‚ñÅ‚ñá‚ñà‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:          Valid Mean_Acc ‚ñÉ‚ñá‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:           learning rate ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_acc ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÜ‚ñà‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñá‚ñá‚ñÑ‚ñÖ
wandb: train_epoch_current_acc ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: train_epoch_summary_acc ‚ñá‚ñÅ‚ñÑ‚ñá‚ñÉ‚ñÅ‚ñá‚ñà‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:              train_loss ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ
wandb:               valid_acc ‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÅ‚ñà‚ñÜ‚ñà‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÜ‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñà‚ñÅ‚ñà‚ñÜ‚ñÜ
wandb:     valid_acc_batch_avg ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñÖ
wandb: valid_epoch_current_acc ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñÅ‚ñÖ‚ñÜ‚ñÖ
wandb:              valid_loss ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     valid_ocean_acc_avg ‚ñÉ‚ñá‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:          Train Mean_Acc 0.61607
wandb:          Valid Mean_Acc 0.4375
wandb:                   epoch 24
wandb:           learning rate 1e-05
wandb:               train_acc 0.5625
wandb: train_epoch_current_acc 0.60938
wandb: train_epoch_summary_acc 0.61607
wandb:              train_loss 0.88125
wandb:               valid_acc 0.5
wandb:     valid_acc_batch_avg 0.5
wandb: valid_epoch_current_acc 0.4375
wandb:              valid_loss 0.72507
wandb:     valid_ocean_acc_avg 0.4375
wandb: 
wandb: üöÄ View run vital-microwave-396 at: https://wandb.ai/hyllbd-1009694687/DeepPersonality/runs/jwohy7td
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230216_000516-jwohy7td/logs
Traceback (most recent call last):
  File "./script/run_exp.py", line 145, in <module>
    main()
  File "./script/run_exp.py", line 55, in main
    runner.run()
  File "/home/zl525/code/DeepPersonality/script/../dpcv/experiment/exp_runner.py", line 206, in run
    self.train()
  File "/home/zl525/code/DeepPersonality/script/../dpcv/experiment/exp_runner.py", line 152, in train
    self.train_epochs(cfg)
  File "/home/zl525/code/DeepPersonality/script/../dpcv/experiment/exp_runner.py", line 117, in train_epochs
    self.trainer.train(self.data_loader["train"], self.model, self.loss_f, self.optimizer, epoch)
  File "/home/zl525/code/DeepPersonality/script/../dpcv/engine/bi_modal_trainer.py", line 345, in train
    loss = loss_f(outputs.cpu(), labels.cpu().float())
  File "/home/zl525/.conda/envs/DeepPersonality/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zl525/.conda/envs/DeepPersonality/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 603, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/home/zl525/.conda/envs/DeepPersonality/lib/python3.8/site-packages/torch/nn/functional.py", line 2915, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
RuntimeError: all elements of input should be between 0 and 1
Changed directory to /home/zl525/code/DeepPersonality/leenote.

JobID: 14449075
======
Time: Thu Feb 16 03:40:28 GMT 2023
Running on master node: cpu-e-1132
Current directory: /home/zl525/code/DeepPersonality/leenote
perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
	LANGUAGE = (unset),
	LC_ALL = (unset),
	LC_CTYPE = "UTF-8",
	LANG = "en_US.UTF-8"
    are supported and installed on your system.
perl: warning: Falling back to the standard locale ("C").

Nodes allocated:
================
cpu-e-1132

numtasks=32, numnodes=1, mpi_tasks_per_node=32 (OMP_NUM_THREADS=1)

Executing command:
==================
mpirun -ppn 32 -np 32  

[mpiexec@cpu-e-1132] set_default_values (../../ui/mpich/utils.c:4663): no executable provided
[mpiexec@cpu-e-1132] HYD_uii_mpx_get_parameters (../../ui/mpich/utils.c:5151): setting default values failed

Usage: ./mpiexec [global opts] [exec1 local opts] : [exec2 local opts] : ...

Global options (passed to all executables):

  Global environment options:
    -genv {name} {value}             environment variable name and value
    -genvlist {env1,env2,...}        environment variable list to pass
    -genvnone                        do not pass any environment variables
    -genvall                         pass all environment variables not managed
                                          by the launcher (default)

  Other global options:
    -f {name} | -hostfile {name}     file containing the host names
    -hosts {host list}               comma separated host list
    -configfile {name}               config file containing MPMD launch options
    -machine {name} | -machinefile {name}
                                     file mapping procs to machines
    -pmi-connect {nocache|lazy-cache|cache}
                                     set the PMI connections mode to use
    -pmi-aggregate                   aggregate PMI messages
    -pmi-noaggregate                 do not  aggregate PMI messages
    -trace {<libraryname>}           trace the application using <libraryname>
                                     profiling library; default is libVT.so
    -trace-imbalance {<libraryname>} trace the application using <libraryname>
                                     imbalance profiling library; default is libVTim.so
    -check-mpi {<libraryname>}       check the application using <libraryname>
                                     checking library; default is libVTmc.so
    -ilp64                           Preload ilp64 wrapper library for support default size of
                                     integer 8 bytes
    -mps                             start statistics gathering for MPI Performance Snapshot (MPS)
    -trace-pt2pt                     collect information about
                                     Point to Point operations
    -trace-collectives               collect information about
                                     Collective operations
    -tune [<confname>]               apply the tuned data produced by
                                     the MPI Tuner utility
    -use-app-topology <statfile>     perform optimized rank placement based statistics
                                     and cluster topology
    -noconf                          do not use any mpiexec's configuration files
    -branch-count {leaves_num}       set the number of children in tree
    -gwdir {dirname}                 working directory to use
    -gpath {dirname}                 path to executable to use
    -gumask {umask}                  mask to perform umask
    -tmpdir {tmpdir}                 temporary directory for cleanup input file
    -cleanup                         create input file for clean up
    -gtool {options}                 apply a tool over the mpi application
    -gtoolfile {file}                apply a tool over the mpi application. Parameters specified in the file


Local options (passed to individual executables):

  Local environment options:
    -env {name} {value}              environment variable name and value
    -envlist {env1,env2,...}         environment variable list to pass
    -envnone                         do not pass any environment variables
    -envall                          pass all environment variables (default)

  Other local options:
    -host {hostname}                 host on which processes are to be run
    -hostos {OS name}                operating system on particular host
    -wdir {dirname}                  working directory to use
    -path {dirname}                  path to executable to use
    -umask {umask}                   mask to perform umask
    -n/-np {value}                   number of processes
    {exec_name} {args}               executable name and arguments


Hydra specific options (treated as global):

  Bootstrap options:
    -bootstrap                       bootstrap server to use
     (ssh rsh pdsh fork slurm srun ll llspawn.stdio lsf blaunch sge qrsh persist service pbsdsh)
    -bootstrap-exec                  executable to use to bootstrap processes
    -bootstrap-exec-args             additional options to pass to bootstrap server
    -prefork                         use pre-fork processes startup method
    -enable-x/-disable-x             enable or disable X forwarding

  Resource management kernel options:
    -rmk                             resource management kernel to use (user slurm srun ll llspawn.stdio lsf blaunch sge qrsh pbs cobalt)

  Processor topology options:
    -binding                         process-to-core binding mode
  Extended fabric control options:
    -rdma                            select RDMA-capable network fabric (dapl). Fallback list is ofa,tcp,tmi,ofi
    -RDMA                            select RDMA-capable network fabric (dapl). Fallback is ofa
    -dapl                            select DAPL-capable network fabric. Fallback list is tcp,tmi,ofa,ofi
    -DAPL                            select DAPL-capable network fabric. No fallback fabric is used
    -ib                              select OFA-capable network fabric. Fallback list is dapl,tcp,tmi,ofi
    -IB                              select OFA-capable network fabric. No fallback fabric is used
    -tmi                             select TMI-capable network fabric. Fallback list is dapl,tcp,ofa,ofi
    -TMI                             select TMI-capable network fabric. No fallback fabric is used
    -mx                              select Myrinet MX* network fabric. Fallback list is dapl,tcp,ofa,ofi
    -MX                              select Myrinet MX* network fabric. No fallback fabric is used
    -psm                             select PSM-capable network fabric. Fallback list is dapl,tcp,ofa,ofi
    -PSM                             select PSM-capable network fabric. No fallback fabric is used
    -psm2                            select Intel* Omni-Path Fabric. Fallback list is dapl,tcp,ofa,ofi
    -PSM2                            select Intel* Omni-Path Fabric. No fallback fabric is used
    -ofi                             select OFI-capable network fabric. Fallback list is tmi,dapl,tcp,ofa
    -OFI                             select OFI-capable network fabric. No fallback fabric is used

  Checkpoint/Restart options:
    -ckpoint {on|off}                enable/disable checkpoints for this run
    -ckpoint-interval                checkpoint interval
    -ckpoint-prefix                  destination for checkpoint files (stable storage, typically a cluster-wide file system)
    -ckpoint-tmp-prefix              temporary/fast/local storage to speed up checkpoints
    -ckpoint-preserve                number of checkpoints to keep (default: 1, i.e. keep only last checkpoint)
    -ckpointlib                      checkpointing library (blcr)
    -ckpoint-logfile                 checkpoint activity/status log file (appended)
    -restart                         restart previously checkpointed application
    -ckpoint-num                     checkpoint number to restart

  Demux engine options:
    -demux                           demux engine (poll select)

  Debugger support options:
    -tv                              run processes under TotalView
    -tva {pid}                       attach existing mpiexec process to TotalView
    -gdb                             run processes under GDB
    -gdba {pid}                      attach existing mpiexec process to GDB
    -gdb-ia                          run processes under Intel IA specific GDB

  Other Hydra options:
    -v | -verbose                    verbose mode
    -V | -version                    show the version
    -info                            build information
    -print-rank-map                  print rank mapping
    -print-all-exitcodes             print exit codes of all processes
    -iface                           network interface to use
    -help                            show this message
    -perhost <n>                     place consecutive <n> processes on each host
    -ppn <n>                         stand for "process per node"; an alias to -perhost <n>
    -grr <n>                         stand for "group round robin"; an alias to -perhost <n>
    -rr                              involve "round robin" startup scheme
    -s <spec>                        redirect stdin to all or 1,2 or 2-4,6 MPI processes (0 by default)
    -ordered-output                  avoid data output intermingling
    -profile                         turn on internal profiling
    -l | -prepend-rank               prepend rank to output
    -prepend-pattern                 prepend pattern to output
    -outfile-pattern                 direct stdout to file
    -errfile-pattern                 direct stderr to file
    -localhost                       local hostname for the launching node
    -nolocal                         avoid running the application processes on the node where mpiexec.hydra started

Intel(R) MPI Library for Linux* OS, Version 2017 Update 3 Build 20170405 (id: 17193)
Copyright (C) 2003-2017, Intel Corporation. All rights reserved.
